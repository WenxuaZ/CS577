{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a27991-5a25-4e2d-a53e-355aaf792b6a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-12-05T14:16:02.471593Z",
     "iopub.status.busy": "2023-12-05T14:16:02.470945Z",
     "iopub.status.idle": "2023-12-05T20:15:14.064575Z",
     "shell.execute_reply": "2023-12-05T20:15:14.063331Z",
     "shell.execute_reply.started": "2023-12-05T14:16:02.471577Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/sunqiao/mymono\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pai/lib/python3.9/site-packages/torchvision/models/_utils.py:252: UserWarning: Accessing the model URLs via the internal dictionary of the module is deprecated since 0.13 and will be removed in 0.15. Please access them via the appropriate Weights Enum instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model named:\n",
      "   lite-mono\n",
      "Models and tensorboard events files are saved to:\n",
      "   ./tmp\n",
      "Training is using:\n",
      "   cuda\n",
      "Using split:\n",
      "   eigen_zhou\n",
      "There are 45619 training items and 4562 validation items\n",
      "\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/sunqiao/mymono/networks/depth_encoder.py:35: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = self.temperature ** (2 * (dim_t // 2) / self.hidden_dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch      0 | examples/s:   1.1 | loss: 0.20615 | time elapsed: 00h00m04s | time left: 00h00m00s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch    250 | examples/s: 104.3 | loss: 0.12414 | time elapsed: 00h00m13s | time left: 07h41m26s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch    500 | examples/s: 103.4 | loss: 0.23405 | time elapsed: 00h00m23s | time left: 06h34m19s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch    750 | examples/s: 100.9 | loss: 0.62217 | time elapsed: 00h00m33s | time left: 06h11m04s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   1000 | examples/s: 106.4 | loss: 0.27663 | time elapsed: 00h00m43s | time left: 05h58m49s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   1250 | examples/s:  99.6 | loss: 0.23921 | time elapsed: 00h00m53s | time left: 05h51m50s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   1500 | examples/s: 105.8 | loss: 0.30374 | time elapsed: 00h01m03s | time left: 05h47m40s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   1750 | examples/s:  91.6 | loss: 0.32157 | time elapsed: 00h01m12s | time left: 05h44m05s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   2000 | examples/s: 104.3 | loss: 0.51153 | time elapsed: 00h01m22s | time left: 05h41m27s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   2250 | examples/s: 103.6 | loss: 0.34248 | time elapsed: 00h01m32s | time left: 05h39m11s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   2500 | examples/s: 106.5 | loss: 0.45199 | time elapsed: 00h01m42s | time left: 05h37m25s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   2750 | examples/s: 102.5 | loss: 0.36953 | time elapsed: 00h01m51s | time left: 05h35m43s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   3000 | examples/s: 103.9 | loss: 0.45303 | time elapsed: 00h02m01s | time left: 05h34m25s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   3250 | examples/s: 101.6 | loss: 0.50665 | time elapsed: 00h02m11s | time left: 05h33m13s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   3500 | examples/s:  90.4 | loss: 0.61825 | time elapsed: 00h02m21s | time left: 05h32m04s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   3750 | examples/s: 106.5 | loss: 0.60815 | time elapsed: 00h02m30s | time left: 05h31m12s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   4000 | examples/s: 105.6 | loss: 0.46399 | time elapsed: 00h02m40s | time left: 05h30m48s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   4250 | examples/s: 104.2 | loss: 0.75837 | time elapsed: 00h02m50s | time left: 05h29m48s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   4500 | examples/s: 105.3 | loss: 0.80678 | time elapsed: 00h03m00s | time left: 05h29m01s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   4750 | examples/s: 104.7 | loss: 0.39219 | time elapsed: 00h03m09s | time left: 05h28m30s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   5000 | examples/s: 105.9 | loss: 0.69590 | time elapsed: 00h03m20s | time left: 05h28m26s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   5250 | examples/s: 101.2 | loss: 0.23884 | time elapsed: 00h03m29s | time left: 05h27m51s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   5500 | examples/s:  98.9 | loss: 0.52098 | time elapsed: 00h03m39s | time left: 05h27m34s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   5750 | examples/s: 101.5 | loss: 0.37412 | time elapsed: 00h03m49s | time left: 05h27m06s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   6000 | examples/s: 103.0 | loss: 0.97765 | time elapsed: 00h03m59s | time left: 05h26m38s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   6250 | examples/s: 104.0 | loss: 0.22806 | time elapsed: 00h04m09s | time left: 05h26m15s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   6500 | examples/s: 100.6 | loss: 0.43808 | time elapsed: 00h04m18s | time left: 05h25m50s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   6750 | examples/s: 100.8 | loss: 0.54961 | time elapsed: 00h04m28s | time left: 05h25m25s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   7000 | examples/s: 104.1 | loss: 0.53456 | time elapsed: 00h04m38s | time left: 05h25m03s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   7250 | examples/s: 104.8 | loss: 0.47826 | time elapsed: 00h04m48s | time left: 05h24m44s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   7500 | examples/s: 103.3 | loss: 0.35346 | time elapsed: 00h04m57s | time left: 05h24m26s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   7750 | examples/s: 104.4 | loss: 0.14338 | time elapsed: 00h05m07s | time left: 05h24m14s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   8000 | examples/s: 101.7 | loss: 0.38821 | time elapsed: 00h05m17s | time left: 05h23m56s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   8250 | examples/s:  90.9 | loss: 0.37182 | time elapsed: 00h05m27s | time left: 05h23m36s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   8500 | examples/s: 104.3 | loss: 0.39300 | time elapsed: 00h05m37s | time left: 05h23m16s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   8750 | examples/s: 106.5 | loss: 0.54625 | time elapsed: 00h05m46s | time left: 05h22m54s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   9000 | examples/s: 101.1 | loss: 0.68417 | time elapsed: 00h05m56s | time left: 05h22m36s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   9250 | examples/s: 104.8 | loss: 0.50373 | time elapsed: 00h06m06s | time left: 05h22m20s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   9500 | examples/s: 104.6 | loss: 0.48334 | time elapsed: 00h06m16s | time left: 05h22m06s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch   9750 | examples/s: 106.1 | loss: 0.59760 | time elapsed: 00h06m25s | time left: 05h21m52s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch  10000 | examples/s: 103.0 | loss: 0.31928 | time elapsed: 00h06m35s | time left: 05h21m37s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch  10250 | examples/s:  99.1 | loss: 0.65071 | time elapsed: 00h06m45s | time left: 05h21m26s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch  10500 | examples/s: 108.1 | loss: 0.72714 | time elapsed: 00h06m55s | time left: 05h21m14s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch  10750 | examples/s: 100.5 | loss: 0.39611 | time elapsed: 00h07m05s | time left: 05h20m57s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch  11000 | examples/s: 104.1 | loss: 0.52416 | time elapsed: 00h07m15s | time left: 05h20m53s\n",
      "epoch   0 | lr 0.000100 |lr_p 0.000100 | batch  11250 | examples/s: 102.8 | loss: 0.41693 | time elapsed: 00h07m25s | time left: 05h20m40s\n",
      "Training\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch      0 | examples/s:  21.1 | loss: 0.55769 | time elapsed: 00h07m33s | time left: 05h22m05s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch    250 | examples/s:  94.2 | loss: 0.38379 | time elapsed: 00h07m43s | time left: 05h21m57s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch    500 | examples/s: 101.7 | loss: 0.57161 | time elapsed: 00h07m53s | time left: 05h21m42s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch    596 | examples/s:  99.8 | loss: 0.87279 | time elapsed: 00h07m56s | time left: 05h21m38s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch    750 | examples/s: 102.4 | loss: 0.41252 | time elapsed: 00h08m02s | time left: 05h21m30s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   1000 | examples/s:  98.9 | loss: 0.39082 | time elapsed: 00h08m12s | time left: 05h21m16s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   1250 | examples/s:  99.1 | loss: 0.38651 | time elapsed: 00h08m22s | time left: 05h21m03s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   1500 | examples/s: 104.1 | loss: 0.46981 | time elapsed: 00h08m32s | time left: 05h20m51s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   1750 | examples/s: 107.3 | loss: 0.70182 | time elapsed: 00h08m42s | time left: 05h20m40s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   2000 | examples/s: 105.0 | loss: 0.52628 | time elapsed: 00h08m52s | time left: 05h20m30s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   2250 | examples/s: 106.0 | loss: 0.54541 | time elapsed: 00h09m02s | time left: 05h20m17s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   2500 | examples/s:  99.9 | loss: 0.33003 | time elapsed: 00h09m12s | time left: 05h20m07s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   2596 | examples/s: 101.9 | loss: 0.60328 | time elapsed: 00h09m15s | time left: 05h20m03s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   2750 | examples/s: 100.7 | loss: 0.96149 | time elapsed: 00h09m22s | time left: 05h19m57s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   3000 | examples/s: 107.0 | loss: 0.67061 | time elapsed: 00h09m32s | time left: 05h19m52s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   3250 | examples/s: 102.5 | loss: 0.55636 | time elapsed: 00h09m41s | time left: 05h19m39s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   3500 | examples/s:  93.7 | loss: 0.56087 | time elapsed: 00h09m51s | time left: 05h19m24s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   3750 | examples/s: 106.1 | loss: 0.24713 | time elapsed: 00h10m01s | time left: 05h19m12s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   4000 | examples/s: 105.0 | loss: 0.28251 | time elapsed: 00h10m11s | time left: 05h19m00s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   4250 | examples/s:  98.6 | loss: 0.82811 | time elapsed: 00h10m21s | time left: 05h18m51s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   4500 | examples/s: 105.8 | loss: 0.80209 | time elapsed: 00h10m31s | time left: 05h18m41s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   4596 | examples/s: 103.1 | loss: 1.03606 | time elapsed: 00h10m35s | time left: 05h18m35s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   4750 | examples/s: 104.1 | loss: 0.48541 | time elapsed: 00h10m41s | time left: 05h18m29s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   5000 | examples/s:  92.9 | loss: 0.43020 | time elapsed: 00h10m51s | time left: 05h18m17s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   5250 | examples/s:  99.8 | loss: 0.63685 | time elapsed: 00h11m00s | time left: 05h18m04s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   5500 | examples/s:  96.7 | loss: 0.92930 | time elapsed: 00h11m10s | time left: 05h17m51s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   5750 | examples/s: 102.4 | loss: 0.59154 | time elapsed: 00h11m20s | time left: 05h17m39s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   6000 | examples/s: 103.0 | loss: 0.54017 | time elapsed: 00h11m30s | time left: 05h17m27s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   6250 | examples/s: 104.0 | loss: 0.45813 | time elapsed: 00h11m40s | time left: 05h17m16s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   6500 | examples/s: 102.6 | loss: 0.52609 | time elapsed: 00h11m50s | time left: 05h17m05s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   6596 | examples/s: 103.4 | loss: 0.48732 | time elapsed: 00h11m53s | time left: 05h17m00s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   6750 | examples/s:  97.6 | loss: 0.43162 | time elapsed: 00h11m59s | time left: 05h16m53s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   7000 | examples/s:  98.1 | loss: 0.60409 | time elapsed: 00h12m09s | time left: 05h16m42s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   7250 | examples/s: 102.1 | loss: 0.50888 | time elapsed: 00h12m19s | time left: 05h16m32s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   7500 | examples/s: 101.5 | loss: 0.33882 | time elapsed: 00h12m29s | time left: 05h16m21s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   7750 | examples/s: 102.2 | loss: 0.82656 | time elapsed: 00h12m39s | time left: 05h16m09s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   8000 | examples/s:  99.8 | loss: 0.33599 | time elapsed: 00h12m49s | time left: 05h15m59s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   8250 | examples/s: 103.2 | loss: 0.45911 | time elapsed: 00h12m59s | time left: 05h15m49s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   8500 | examples/s: 102.0 | loss: 0.71029 | time elapsed: 00h13m09s | time left: 05h15m38s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch   8596 | examples/s:  94.3 | loss: 0.51233 | time elapsed: 00h13m12s | time left: 05h15m34s\n",
      "epoch   1 | lr 0.000099 |lr_p 0.000099 | batch  10596 | examples/s: 105.9 | loss: 0.33377 | time elapsed: 00h14m31s | time left: 05h14m03s\n",
      "Training\n",
      "epoch   2 | lr 0.000098 |lr_p 0.000098 | batch   1192 | examples/s: 101.1 | loss: 0.34211 | time elapsed: 00h15m52s | time left: 05h13m17s\n",
      "epoch   2 | lr 0.000098 |lr_p 0.000098 | batch   3192 | examples/s:  99.2 | loss: 0.85638 | time elapsed: 00h17m11s | time left: 05h11m46s\n",
      "epoch   2 | lr 0.000098 |lr_p 0.000098 | batch   5192 | examples/s: 103.6 | loss: 0.31263 | time elapsed: 00h18m29s | time left: 05h10m10s\n",
      "epoch   2 | lr 0.000098 |lr_p 0.000098 | batch   7192 | examples/s: 102.8 | loss: 0.57371 | time elapsed: 00h19m47s | time left: 05h08m26s\n",
      "epoch   2 | lr 0.000098 |lr_p 0.000098 | batch   9192 | examples/s: 107.2 | loss: 0.98736 | time elapsed: 00h21m05s | time left: 05h06m50s\n",
      "epoch   2 | lr 0.000098 |lr_p 0.000098 | batch  11192 | examples/s:  96.6 | loss: 0.44031 | time elapsed: 00h22m23s | time left: 05h05m15s\n",
      "Training\n",
      "epoch   3 | lr 0.000096 |lr_p 0.000096 | batch   1788 | examples/s:  99.7 | loss: 0.51225 | time elapsed: 00h23m45s | time left: 05h04m32s\n",
      "epoch   3 | lr 0.000096 |lr_p 0.000096 | batch   3788 | examples/s: 100.5 | loss: 0.34387 | time elapsed: 00h25m03s | time left: 05h03m09s\n",
      "epoch   3 | lr 0.000096 |lr_p 0.000096 | batch   5788 | examples/s: 104.8 | loss: 0.41121 | time elapsed: 00h26m22s | time left: 05h01m44s\n",
      "epoch   3 | lr 0.000096 |lr_p 0.000096 | batch   7788 | examples/s: 102.5 | loss: 0.64221 | time elapsed: 00h27m40s | time left: 05h00m17s\n",
      "epoch   3 | lr 0.000096 |lr_p 0.000096 | batch   9788 | examples/s:  99.8 | loss: 0.56477 | time elapsed: 00h29m00s | time left: 04h59m05s\n",
      "Training\n",
      "epoch   4 | lr 0.000094 |lr_p 0.000094 | batch    384 | examples/s:  99.7 | loss: 0.36104 | time elapsed: 00h30m22s | time left: 04h58m11s\n",
      "epoch   4 | lr 0.000094 |lr_p 0.000094 | batch   2384 | examples/s: 104.5 | loss: 0.62724 | time elapsed: 00h31m41s | time left: 04h56m50s\n",
      "epoch   4 | lr 0.000094 |lr_p 0.000094 | batch   4384 | examples/s: 103.9 | loss: 0.44416 | time elapsed: 00h33m00s | time left: 04h55m27s\n",
      "epoch   4 | lr 0.000094 |lr_p 0.000094 | batch   6384 | examples/s: 101.2 | loss: 0.57530 | time elapsed: 00h34m19s | time left: 04h54m07s\n",
      "epoch   4 | lr 0.000094 |lr_p 0.000094 | batch   8384 | examples/s: 103.8 | loss: 0.32936 | time elapsed: 00h35m39s | time left: 04h52m51s\n",
      "epoch   4 | lr 0.000094 |lr_p 0.000094 | batch  10384 | examples/s:  94.6 | loss: 0.52077 | time elapsed: 00h36m57s | time left: 04h51m29s\n",
      "Training\n",
      "epoch   5 | lr 0.000091 |lr_p 0.000092 | batch    980 | examples/s:  96.4 | loss: 0.56453 | time elapsed: 00h38m19s | time left: 04h50m29s\n",
      "epoch   5 | lr 0.000091 |lr_p 0.000092 | batch   2980 | examples/s: 102.1 | loss: 0.51823 | time elapsed: 00h39m38s | time left: 04h49m10s\n",
      "epoch   5 | lr 0.000091 |lr_p 0.000092 | batch   4980 | examples/s: 102.4 | loss: 0.43740 | time elapsed: 00h40m57s | time left: 04h47m48s\n",
      "epoch   5 | lr 0.000091 |lr_p 0.000092 | batch   6980 | examples/s: 103.3 | loss: 0.65279 | time elapsed: 00h42m18s | time left: 04h46m34s\n",
      "epoch   5 | lr 0.000091 |lr_p 0.000092 | batch   8980 | examples/s:  95.9 | loss: 0.76437 | time elapsed: 00h43m37s | time left: 04h45m18s\n",
      "epoch   5 | lr 0.000091 |lr_p 0.000092 | batch  10980 | examples/s:  97.3 | loss: 0.37074 | time elapsed: 00h44m57s | time left: 04h44m03s\n",
      "Training\n",
      "epoch   6 | lr 0.000089 |lr_p 0.000089 | batch   1576 | examples/s:  95.4 | loss: 0.42072 | time elapsed: 00h46m19s | time left: 04h42m58s\n",
      "epoch   6 | lr 0.000089 |lr_p 0.000089 | batch   3576 | examples/s: 106.7 | loss: 0.57686 | time elapsed: 00h47m39s | time left: 04h41m41s\n",
      "epoch   6 | lr 0.000089 |lr_p 0.000089 | batch   5576 | examples/s:  90.7 | loss: 0.37693 | time elapsed: 00h48m58s | time left: 04h40m20s\n",
      "epoch   6 | lr 0.000089 |lr_p 0.000089 | batch   7576 | examples/s:  96.7 | loss: 0.47295 | time elapsed: 00h50m18s | time left: 04h39m05s\n",
      "epoch   6 | lr 0.000089 |lr_p 0.000089 | batch   9576 | examples/s: 100.4 | loss: 0.27683 | time elapsed: 00h51m38s | time left: 04h37m46s\n",
      "Training\n",
      "epoch   7 | lr 0.000085 |lr_p 0.000086 | batch    172 | examples/s: 105.0 | loss: 0.32946 | time elapsed: 00h53m00s | time left: 04h36m40s\n",
      "epoch   7 | lr 0.000085 |lr_p 0.000086 | batch   2172 | examples/s: 100.1 | loss: 0.65826 | time elapsed: 00h54m19s | time left: 04h35m18s\n",
      "epoch   7 | lr 0.000085 |lr_p 0.000086 | batch   4172 | examples/s:  99.8 | loss: 0.23194 | time elapsed: 00h55m38s | time left: 04h33m59s\n",
      "epoch   7 | lr 0.000085 |lr_p 0.000086 | batch   6172 | examples/s:  95.7 | loss: 0.61961 | time elapsed: 00h56m58s | time left: 04h32m41s\n",
      "epoch   7 | lr 0.000085 |lr_p 0.000086 | batch   8172 | examples/s: 101.6 | loss: 0.38886 | time elapsed: 00h58m18s | time left: 04h31m22s\n",
      "epoch   7 | lr 0.000085 |lr_p 0.000086 | batch  10172 | examples/s: 102.1 | loss: 0.39918 | time elapsed: 00h59m37s | time left: 04h30m02s\n",
      "Training\n",
      "epoch   8 | lr 0.000082 |lr_p 0.000083 | batch    768 | examples/s: 103.7 | loss: 0.37604 | time elapsed: 01h00m58s | time left: 04h28m50s\n",
      "epoch   8 | lr 0.000082 |lr_p 0.000083 | batch   2768 | examples/s:  96.8 | loss: 0.33777 | time elapsed: 01h02m19s | time left: 04h27m36s\n",
      "epoch   8 | lr 0.000082 |lr_p 0.000083 | batch   4768 | examples/s:  99.1 | loss: 0.26284 | time elapsed: 01h03m39s | time left: 04h26m16s\n",
      "epoch   8 | lr 0.000082 |lr_p 0.000083 | batch   6768 | examples/s: 104.3 | loss: 0.71091 | time elapsed: 01h04m59s | time left: 04h24m58s\n",
      "epoch   8 | lr 0.000082 |lr_p 0.000083 | batch   8768 | examples/s: 104.4 | loss: 0.37017 | time elapsed: 01h06m18s | time left: 04h23m40s\n",
      "epoch   8 | lr 0.000082 |lr_p 0.000083 | batch  10768 | examples/s:  96.0 | loss: 0.28578 | time elapsed: 01h07m37s | time left: 04h22m17s\n",
      "Training\n",
      "epoch   9 | lr 0.000078 |lr_p 0.000079 | batch   1364 | examples/s: 104.9 | loss: 0.30243 | time elapsed: 01h08m58s | time left: 04h21m04s\n",
      "epoch   9 | lr 0.000078 |lr_p 0.000079 | batch   3364 | examples/s: 101.7 | loss: 0.36172 | time elapsed: 01h10m18s | time left: 04h19m44s\n",
      "epoch   9 | lr 0.000078 |lr_p 0.000079 | batch   5364 | examples/s: 104.3 | loss: 0.42035 | time elapsed: 01h11m33s | time left: 04h18m08s\n",
      "epoch   9 | lr 0.000078 |lr_p 0.000079 | batch   7364 | examples/s: 112.3 | loss: 0.46136 | time elapsed: 01h12m44s | time left: 04h16m17s\n",
      "epoch   9 | lr 0.000078 |lr_p 0.000079 | batch   9364 | examples/s: 115.1 | loss: 1.12097 | time elapsed: 01h13m54s | time left: 04h14m27s\n",
      "epoch   9 | lr 0.000078 |lr_p 0.000079 | batch  11364 | examples/s: 109.6 | loss: 0.50139 | time elapsed: 01h15m05s | time left: 04h12m39s\n",
      "Training\n",
      "epoch  10 | lr 0.000073 |lr_p 0.000075 | batch   1960 | examples/s: 111.4 | loss: 0.52033 | time elapsed: 01h16m18s | time left: 04h11m01s\n",
      "epoch  10 | lr 0.000073 |lr_p 0.000075 | batch   3960 | examples/s: 113.3 | loss: 0.73017 | time elapsed: 01h17m29s | time left: 04h09m18s\n",
      "epoch  10 | lr 0.000073 |lr_p 0.000075 | batch   5960 | examples/s: 116.0 | loss: 0.39833 | time elapsed: 01h18m41s | time left: 04h07m36s\n",
      "epoch  10 | lr 0.000073 |lr_p 0.000075 | batch   7960 | examples/s: 110.1 | loss: 0.46344 | time elapsed: 01h19m53s | time left: 04h05m57s\n",
      "epoch  10 | lr 0.000073 |lr_p 0.000075 | batch   9960 | examples/s: 117.6 | loss: 0.38397 | time elapsed: 01h21m05s | time left: 04h04m18s\n",
      "Training\n",
      "epoch  11 | lr 0.000069 |lr_p 0.000071 | batch    556 | examples/s: 111.0 | loss: 0.59284 | time elapsed: 01h22m19s | time left: 04h02m46s\n",
      "epoch  11 | lr 0.000069 |lr_p 0.000071 | batch   2556 | examples/s: 111.8 | loss: 0.40175 | time elapsed: 01h23m32s | time left: 04h01m13s\n",
      "epoch  11 | lr 0.000069 |lr_p 0.000071 | batch   4556 | examples/s: 112.1 | loss: 0.40041 | time elapsed: 01h24m45s | time left: 03h59m41s\n",
      "epoch  11 | lr 0.000069 |lr_p 0.000071 | batch   6556 | examples/s: 108.3 | loss: 0.38449 | time elapsed: 01h25m58s | time left: 03h58m08s\n",
      "epoch  11 | lr 0.000069 |lr_p 0.000071 | batch   8556 | examples/s: 103.2 | loss: 0.51516 | time elapsed: 01h27m11s | time left: 03h56m34s\n",
      "epoch  11 | lr 0.000069 |lr_p 0.000071 | batch  10556 | examples/s: 111.2 | loss: 0.76401 | time elapsed: 01h28m23s | time left: 03h55m00s\n",
      "Training\n",
      "epoch  12 | lr 0.000064 |lr_p 0.000066 | batch   1152 | examples/s: 106.6 | loss: 0.94782 | time elapsed: 01h29m38s | time left: 03h53m34s\n",
      "epoch  12 | lr 0.000064 |lr_p 0.000066 | batch   3152 | examples/s: 112.9 | loss: 0.52948 | time elapsed: 01h30m50s | time left: 03h52m02s\n",
      "epoch  12 | lr 0.000064 |lr_p 0.000066 | batch   5152 | examples/s:  92.4 | loss: 0.46954 | time elapsed: 01h32m03s | time left: 03h50m31s\n",
      "epoch  12 | lr 0.000064 |lr_p 0.000066 | batch   7152 | examples/s: 114.0 | loss: 0.38311 | time elapsed: 01h33m15s | time left: 03h48m59s\n",
      "epoch  12 | lr 0.000064 |lr_p 0.000066 | batch   9152 | examples/s: 115.5 | loss: 0.45565 | time elapsed: 01h34m27s | time left: 03h47m27s\n",
      "epoch  12 | lr 0.000064 |lr_p 0.000066 | batch  11152 | examples/s: 116.9 | loss: 0.37749 | time elapsed: 01h35m38s | time left: 03h45m56s\n",
      "Training\n",
      "epoch  13 | lr 0.000060 |lr_p 0.000062 | batch   1748 | examples/s: 113.2 | loss: 0.46985 | time elapsed: 01h36m53s | time left: 03h44m31s\n",
      "epoch  13 | lr 0.000060 |lr_p 0.000062 | batch   3748 | examples/s: 114.1 | loss: 0.54206 | time elapsed: 01h38m06s | time left: 03h43m04s\n",
      "epoch  13 | lr 0.000060 |lr_p 0.000062 | batch   5748 | examples/s: 109.0 | loss: 0.22653 | time elapsed: 01h39m19s | time left: 03h41m35s\n",
      "epoch  13 | lr 0.000060 |lr_p 0.000062 | batch   7748 | examples/s: 115.8 | loss: 0.65166 | time elapsed: 01h40m30s | time left: 03h40m06s\n",
      "epoch  13 | lr 0.000060 |lr_p 0.000062 | batch   9748 | examples/s: 112.4 | loss: 0.43550 | time elapsed: 01h41m42s | time left: 03h38m36s\n",
      "Training\n",
      "epoch  14 | lr 0.000055 |lr_p 0.000057 | batch    344 | examples/s: 106.5 | loss: 0.35515 | time elapsed: 01h42m57s | time left: 03h37m13s\n",
      "epoch  14 | lr 0.000055 |lr_p 0.000057 | batch   2344 | examples/s: 109.8 | loss: 0.22190 | time elapsed: 01h44m11s | time left: 03h35m49s\n",
      "epoch  14 | lr 0.000055 |lr_p 0.000057 | batch   4344 | examples/s: 106.4 | loss: 0.55782 | time elapsed: 01h45m23s | time left: 03h34m23s\n",
      "epoch  14 | lr 0.000055 |lr_p 0.000057 | batch   6344 | examples/s: 111.4 | loss: 0.32657 | time elapsed: 01h46m35s | time left: 03h32m56s\n",
      "epoch  14 | lr 0.000055 |lr_p 0.000057 | batch   8344 | examples/s: 113.8 | loss: 0.40553 | time elapsed: 01h47m47s | time left: 03h31m28s\n",
      "epoch  14 | lr 0.000055 |lr_p 0.000057 | batch  10344 | examples/s: 112.1 | loss: 0.51742 | time elapsed: 01h48m58s | time left: 03h30m00s\n",
      "Training\n",
      "epoch  15 | lr 0.000050 |lr_p 0.000053 | batch    940 | examples/s: 105.7 | loss: 0.56769 | time elapsed: 01h50m13s | time left: 03h28m40s\n",
      "epoch  15 | lr 0.000050 |lr_p 0.000053 | batch   2940 | examples/s: 103.5 | loss: 0.34662 | time elapsed: 01h51m26s | time left: 03h27m15s\n",
      "epoch  15 | lr 0.000050 |lr_p 0.000053 | batch   4940 | examples/s:  92.9 | loss: 0.53990 | time elapsed: 01h52m39s | time left: 03h25m50s\n",
      "epoch  15 | lr 0.000050 |lr_p 0.000053 | batch   6940 | examples/s: 113.8 | loss: 0.43283 | time elapsed: 01h53m50s | time left: 03h24m24s\n",
      "epoch  15 | lr 0.000050 |lr_p 0.000053 | batch   8940 | examples/s: 113.4 | loss: 0.39722 | time elapsed: 01h55m03s | time left: 03h23m00s\n",
      "epoch  15 | lr 0.000050 |lr_p 0.000053 | batch  10940 | examples/s: 111.0 | loss: 0.66041 | time elapsed: 01h56m15s | time left: 03h21m35s\n",
      "Training\n",
      "epoch  16 | lr 0.000045 |lr_p 0.000048 | batch   1536 | examples/s: 105.4 | loss: 0.56372 | time elapsed: 01h57m30s | time left: 03h20m15s\n",
      "epoch  16 | lr 0.000045 |lr_p 0.000048 | batch   3536 | examples/s: 113.1 | loss: 0.31197 | time elapsed: 01h58m43s | time left: 03h18m53s\n",
      "epoch  16 | lr 0.000045 |lr_p 0.000048 | batch   5536 | examples/s: 107.3 | loss: 0.47659 | time elapsed: 01h59m55s | time left: 03h17m30s\n",
      "epoch  16 | lr 0.000045 |lr_p 0.000048 | batch   7536 | examples/s: 112.9 | loss: 0.63046 | time elapsed: 02h01m09s | time left: 03h16m08s\n",
      "epoch  16 | lr 0.000045 |lr_p 0.000048 | batch   9536 | examples/s: 111.3 | loss: 0.57245 | time elapsed: 02h02m21s | time left: 03h14m44s\n",
      "Training\n",
      "epoch  17 | lr 0.000041 |lr_p 0.000044 | batch    132 | examples/s: 110.6 | loss: 0.50303 | time elapsed: 02h03m34s | time left: 03h13m24s\n",
      "epoch  17 | lr 0.000041 |lr_p 0.000044 | batch   2132 | examples/s: 106.9 | loss: 0.39004 | time elapsed: 02h04m48s | time left: 03h12m03s\n",
      "epoch  17 | lr 0.000041 |lr_p 0.000044 | batch   4132 | examples/s: 105.1 | loss: 0.71872 | time elapsed: 02h06m01s | time left: 03h10m41s\n",
      "epoch  17 | lr 0.000041 |lr_p 0.000044 | batch   6132 | examples/s: 114.0 | loss: 0.67266 | time elapsed: 02h07m15s | time left: 03h09m21s\n",
      "epoch  17 | lr 0.000041 |lr_p 0.000044 | batch   8132 | examples/s: 113.8 | loss: 0.37485 | time elapsed: 02h08m28s | time left: 03h08m00s\n",
      "epoch  17 | lr 0.000041 |lr_p 0.000044 | batch  10132 | examples/s:  96.1 | loss: 0.23352 | time elapsed: 02h09m40s | time left: 03h06m38s\n",
      "Training\n",
      "epoch  18 | lr 0.000036 |lr_p 0.000039 | batch    728 | examples/s: 108.7 | loss: 0.30353 | time elapsed: 02h10m55s | time left: 03h05m19s\n",
      "epoch  18 | lr 0.000036 |lr_p 0.000039 | batch   2728 | examples/s: 111.0 | loss: 0.74875 | time elapsed: 02h12m08s | time left: 03h03m58s\n",
      "epoch  18 | lr 0.000036 |lr_p 0.000039 | batch   4728 | examples/s: 109.7 | loss: 0.55153 | time elapsed: 02h13m21s | time left: 03h02m37s\n",
      "epoch  18 | lr 0.000036 |lr_p 0.000039 | batch   6728 | examples/s:  91.7 | loss: 0.45575 | time elapsed: 02h14m33s | time left: 03h01m16s\n",
      "epoch  18 | lr 0.000036 |lr_p 0.000039 | batch   8728 | examples/s: 107.3 | loss: 0.32482 | time elapsed: 02h15m45s | time left: 02h59m54s\n",
      "epoch  18 | lr 0.000036 |lr_p 0.000039 | batch  10728 | examples/s: 113.2 | loss: 0.29835 | time elapsed: 02h16m57s | time left: 02h58m33s\n",
      "Training\n",
      "epoch  19 | lr 0.000032 |lr_p 0.000035 | batch   1324 | examples/s: 114.9 | loss: 0.44576 | time elapsed: 02h18m12s | time left: 02h57m16s\n",
      "epoch  19 | lr 0.000032 |lr_p 0.000035 | batch   3324 | examples/s: 110.6 | loss: 0.53154 | time elapsed: 02h19m25s | time left: 02h55m55s\n",
      "epoch  19 | lr 0.000032 |lr_p 0.000035 | batch   5324 | examples/s: 115.5 | loss: 0.78353 | time elapsed: 02h20m37s | time left: 02h54m34s\n",
      "epoch  19 | lr 0.000032 |lr_p 0.000035 | batch   7324 | examples/s: 106.3 | loss: 0.72005 | time elapsed: 02h21m50s | time left: 02h53m14s\n",
      "epoch  19 | lr 0.000032 |lr_p 0.000035 | batch   9324 | examples/s: 106.5 | loss: 0.29777 | time elapsed: 02h23m02s | time left: 02h51m53s\n",
      "epoch  19 | lr 0.000032 |lr_p 0.000035 | batch  11324 | examples/s: 114.4 | loss: 0.31344 | time elapsed: 02h24m14s | time left: 02h50m33s\n",
      "Training\n",
      "epoch  20 | lr 0.000027 |lr_p 0.000031 | batch   1920 | examples/s: 114.1 | loss: 0.30517 | time elapsed: 02h25m29s | time left: 02h49m16s\n",
      "epoch  20 | lr 0.000027 |lr_p 0.000031 | batch   3920 | examples/s: 112.8 | loss: 0.62174 | time elapsed: 02h26m42s | time left: 02h47m56s\n",
      "epoch  20 | lr 0.000027 |lr_p 0.000031 | batch   5920 | examples/s: 114.6 | loss: 0.15017 | time elapsed: 02h27m54s | time left: 02h46m36s\n",
      "epoch  20 | lr 0.000027 |lr_p 0.000031 | batch   7920 | examples/s: 112.7 | loss: 0.35059 | time elapsed: 02h29m06s | time left: 02h45m16s\n",
      "epoch  20 | lr 0.000027 |lr_p 0.000031 | batch   9920 | examples/s: 112.9 | loss: 0.60489 | time elapsed: 02h30m17s | time left: 02h43m56s\n",
      "Training\n",
      "epoch  21 | lr 0.000023 |lr_p 0.000027 | batch    516 | examples/s: 114.3 | loss: 0.25326 | time elapsed: 02h31m32s | time left: 02h42m39s\n",
      "epoch  21 | lr 0.000023 |lr_p 0.000027 | batch   2516 | examples/s: 114.3 | loss: 0.47149 | time elapsed: 02h32m44s | time left: 02h41m19s\n",
      "epoch  21 | lr 0.000023 |lr_p 0.000027 | batch   4516 | examples/s: 109.7 | loss: 0.51162 | time elapsed: 02h33m56s | time left: 02h40m00s\n",
      "epoch  21 | lr 0.000023 |lr_p 0.000027 | batch   6516 | examples/s: 114.7 | loss: 0.49498 | time elapsed: 02h35m09s | time left: 02h38m41s\n",
      "epoch  21 | lr 0.000023 |lr_p 0.000027 | batch   8516 | examples/s: 112.8 | loss: 0.23164 | time elapsed: 02h36m21s | time left: 02h37m21s\n",
      "epoch  21 | lr 0.000023 |lr_p 0.000027 | batch  10516 | examples/s: 113.7 | loss: 0.57831 | time elapsed: 02h37m33s | time left: 02h36m02s\n",
      "Training\n",
      "epoch  22 | lr 0.000020 |lr_p 0.000024 | batch   1112 | examples/s: 108.8 | loss: 0.71911 | time elapsed: 02h38m48s | time left: 02h34m46s\n",
      "epoch  22 | lr 0.000020 |lr_p 0.000024 | batch   3112 | examples/s: 107.6 | loss: 0.46787 | time elapsed: 02h39m59s | time left: 02h33m26s\n",
      "epoch  22 | lr 0.000020 |lr_p 0.000024 | batch   5112 | examples/s: 112.8 | loss: 0.45450 | time elapsed: 02h41m11s | time left: 02h32m07s\n",
      "epoch  22 | lr 0.000020 |lr_p 0.000024 | batch   7112 | examples/s: 112.6 | loss: 0.62747 | time elapsed: 02h42m23s | time left: 02h30m48s\n",
      "epoch  22 | lr 0.000020 |lr_p 0.000024 | batch   9112 | examples/s: 115.6 | loss: 0.57191 | time elapsed: 02h43m35s | time left: 02h29m30s\n",
      "epoch  22 | lr 0.000020 |lr_p 0.000024 | batch  11112 | examples/s: 113.8 | loss: 0.42776 | time elapsed: 02h44m48s | time left: 02h28m11s\n",
      "Training\n",
      "epoch  23 | lr 0.000016 |lr_p 0.000021 | batch   1708 | examples/s: 106.1 | loss: 0.72683 | time elapsed: 02h46m03s | time left: 02h26m56s\n",
      "epoch  23 | lr 0.000016 |lr_p 0.000021 | batch   3708 | examples/s: 116.4 | loss: 0.54990 | time elapsed: 02h47m15s | time left: 02h25m37s\n",
      "epoch  23 | lr 0.000016 |lr_p 0.000021 | batch   5708 | examples/s: 115.7 | loss: 0.41523 | time elapsed: 02h48m26s | time left: 02h24m18s\n",
      "epoch  23 | lr 0.000016 |lr_p 0.000021 | batch   7708 | examples/s: 113.6 | loss: 0.36754 | time elapsed: 02h49m38s | time left: 02h22m59s\n",
      "epoch  23 | lr 0.000016 |lr_p 0.000021 | batch   9708 | examples/s: 111.9 | loss: 0.33181 | time elapsed: 02h50m50s | time left: 02h21m41s\n",
      "Training\n",
      "epoch  24 | lr 0.000014 |lr_p 0.000018 | batch    304 | examples/s: 112.1 | loss: 0.64990 | time elapsed: 02h52m04s | time left: 02h20m25s\n",
      "epoch  24 | lr 0.000014 |lr_p 0.000018 | batch   2304 | examples/s: 109.3 | loss: 0.46897 | time elapsed: 02h53m18s | time left: 02h19m08s\n",
      "epoch  24 | lr 0.000014 |lr_p 0.000018 | batch   4304 | examples/s: 111.0 | loss: 0.57997 | time elapsed: 02h54m31s | time left: 02h17m51s\n",
      "epoch  24 | lr 0.000014 |lr_p 0.000018 | batch   6304 | examples/s: 109.0 | loss: 0.75668 | time elapsed: 02h55m43s | time left: 02h16m34s\n",
      "epoch  24 | lr 0.000014 |lr_p 0.000018 | batch   8304 | examples/s: 111.1 | loss: 0.34847 | time elapsed: 02h56m56s | time left: 02h15m16s\n",
      "epoch  24 | lr 0.000014 |lr_p 0.000018 | batch  10304 | examples/s: 113.6 | loss: 0.69125 | time elapsed: 02h58m08s | time left: 02h13m58s\n",
      "Training\n",
      "epoch  25 | lr 0.000011 |lr_p 0.000016 | batch    900 | examples/s: 105.8 | loss: 0.38796 | time elapsed: 02h59m23s | time left: 02h12m43s\n",
      "epoch  25 | lr 0.000011 |lr_p 0.000016 | batch   2900 | examples/s: 110.9 | loss: 0.71663 | time elapsed: 03h00m36s | time left: 02h11m26s\n",
      "epoch  25 | lr 0.000011 |lr_p 0.000016 | batch   4900 | examples/s: 113.7 | loss: 0.99163 | time elapsed: 03h01m47s | time left: 02h10m08s\n",
      "epoch  25 | lr 0.000011 |lr_p 0.000016 | batch   6900 | examples/s: 114.5 | loss: 0.27221 | time elapsed: 03h02m59s | time left: 02h08m50s\n",
      "epoch  25 | lr 0.000011 |lr_p 0.000016 | batch   8900 | examples/s: 113.2 | loss: 0.46326 | time elapsed: 03h04m10s | time left: 02h07m32s\n",
      "epoch  25 | lr 0.000011 |lr_p 0.000016 | batch  10900 | examples/s: 112.6 | loss: 0.61697 | time elapsed: 03h05m22s | time left: 02h06m15s\n",
      "Training\n",
      "epoch  26 | lr 0.000009 |lr_p 0.000014 | batch   1496 | examples/s: 113.6 | loss: 0.81528 | time elapsed: 03h06m37s | time left: 02h05m00s\n",
      "epoch  26 | lr 0.000009 |lr_p 0.000014 | batch   3496 | examples/s: 109.1 | loss: 0.33061 | time elapsed: 03h07m50s | time left: 02h03m43s\n",
      "epoch  26 | lr 0.000009 |lr_p 0.000014 | batch   5496 | examples/s: 109.8 | loss: 0.42606 | time elapsed: 03h09m02s | time left: 02h02m26s\n",
      "epoch  26 | lr 0.000009 |lr_p 0.000014 | batch   7496 | examples/s: 114.3 | loss: 0.69500 | time elapsed: 03h10m14s | time left: 02h01m09s\n",
      "epoch  26 | lr 0.000009 |lr_p 0.000014 | batch   9496 | examples/s: 105.0 | loss: 0.44754 | time elapsed: 03h11m26s | time left: 01h59m52s\n",
      "Training\n",
      "epoch  27 | lr 0.000007 |lr_p 0.000012 | batch     92 | examples/s: 112.9 | loss: 0.59403 | time elapsed: 03h12m40s | time left: 01h58m36s\n",
      "epoch  27 | lr 0.000007 |lr_p 0.000012 | batch   2092 | examples/s: 111.4 | loss: 0.41021 | time elapsed: 03h13m54s | time left: 01h57m20s\n",
      "epoch  27 | lr 0.000007 |lr_p 0.000012 | batch   4092 | examples/s: 111.3 | loss: 0.71705 | time elapsed: 03h15m06s | time left: 01h56m04s\n",
      "epoch  27 | lr 0.000007 |lr_p 0.000012 | batch   6092 | examples/s: 109.9 | loss: 0.60577 | time elapsed: 03h16m19s | time left: 01h54m47s\n",
      "epoch  27 | lr 0.000007 |lr_p 0.000012 | batch   8092 | examples/s: 113.0 | loss: 0.41555 | time elapsed: 03h17m31s | time left: 01h53m30s\n",
      "epoch  27 | lr 0.000007 |lr_p 0.000012 | batch  10092 | examples/s: 114.9 | loss: 0.14415 | time elapsed: 03h18m43s | time left: 01h52m14s\n",
      "Training\n",
      "epoch  28 | lr 0.000006 |lr_p 0.000011 | batch    688 | examples/s: 113.8 | loss: 0.65281 | time elapsed: 03h19m58s | time left: 01h50m59s\n",
      "epoch  28 | lr 0.000006 |lr_p 0.000011 | batch   2688 | examples/s:  89.0 | loss: 0.57737 | time elapsed: 03h21m11s | time left: 01h49m42s\n",
      "epoch  28 | lr 0.000006 |lr_p 0.000011 | batch   4688 | examples/s: 112.8 | loss: 0.60705 | time elapsed: 03h22m22s | time left: 01h48m26s\n",
      "epoch  28 | lr 0.000006 |lr_p 0.000011 | batch   6688 | examples/s: 108.0 | loss: 0.34504 | time elapsed: 03h23m34s | time left: 01h47m09s\n",
      "epoch  28 | lr 0.000006 |lr_p 0.000011 | batch   8688 | examples/s: 116.2 | loss: 0.59514 | time elapsed: 03h24m45s | time left: 01h45m52s\n",
      "epoch  28 | lr 0.000006 |lr_p 0.000011 | batch  10688 | examples/s: 111.1 | loss: 0.27837 | time elapsed: 03h25m58s | time left: 01h44m36s\n",
      "Training\n",
      "epoch  29 | lr 0.000005 |lr_p 0.000010 | batch   1284 | examples/s: 106.3 | loss: 0.64420 | time elapsed: 03h27m12s | time left: 01h43m21s\n",
      "epoch  29 | lr 0.000005 |lr_p 0.000010 | batch   3284 | examples/s:  91.3 | loss: 0.20391 | time elapsed: 03h28m26s | time left: 01h42m05s\n",
      "epoch  29 | lr 0.000005 |lr_p 0.000010 | batch   5284 | examples/s: 109.8 | loss: 0.65798 | time elapsed: 03h29m39s | time left: 01h40m49s\n",
      "epoch  29 | lr 0.000005 |lr_p 0.000010 | batch   7284 | examples/s: 115.7 | loss: 0.32823 | time elapsed: 03h30m50s | time left: 01h39m33s\n",
      "epoch  29 | lr 0.000005 |lr_p 0.000010 | batch   9284 | examples/s: 108.7 | loss: 0.55189 | time elapsed: 03h32m02s | time left: 01h38m17s\n",
      "epoch  29 | lr 0.000005 |lr_p 0.000010 | batch  11284 | examples/s: 111.6 | loss: 0.42040 | time elapsed: 03h33m14s | time left: 01h37m01s\n",
      "Training\n",
      "epoch  30 | lr 0.000090 |lr_p 0.000090 | batch   1880 | examples/s: 103.5 | loss: 0.59631 | time elapsed: 03h34m32s | time left: 01h35m47s\n",
      "epoch  30 | lr 0.000090 |lr_p 0.000090 | batch   3880 | examples/s: 102.2 | loss: 0.45386 | time elapsed: 03h35m50s | time left: 01h34m34s\n",
      "epoch  30 | lr 0.000090 |lr_p 0.000090 | batch   5880 | examples/s: 102.2 | loss: 0.52599 | time elapsed: 03h37m09s | time left: 01h33m21s\n",
      "epoch  30 | lr 0.000090 |lr_p 0.000090 | batch   7880 | examples/s: 105.8 | loss: 0.90160 | time elapsed: 03h38m27s | time left: 01h32m07s\n",
      "epoch  30 | lr 0.000090 |lr_p 0.000090 | batch   9880 | examples/s:  99.8 | loss: 0.30211 | time elapsed: 03h39m45s | time left: 01h30m53s\n",
      "Training\n",
      "epoch  31 | lr 0.000090 |lr_p 0.000090 | batch    476 | examples/s: 103.2 | loss: 0.63951 | time elapsed: 03h41m06s | time left: 01h29m41s\n",
      "epoch  31 | lr 0.000090 |lr_p 0.000090 | batch   2476 | examples/s: 102.5 | loss: 0.23640 | time elapsed: 03h42m24s | time left: 01h28m27s\n",
      "epoch  31 | lr 0.000090 |lr_p 0.000090 | batch   4476 | examples/s: 107.8 | loss: 0.54902 | time elapsed: 03h43m41s | time left: 01h27m13s\n",
      "epoch  31 | lr 0.000090 |lr_p 0.000090 | batch   6476 | examples/s: 102.4 | loss: 0.39028 | time elapsed: 03h44m59s | time left: 01h25m59s\n",
      "epoch  31 | lr 0.000090 |lr_p 0.000090 | batch   8476 | examples/s:  99.4 | loss: 0.52520 | time elapsed: 03h46m16s | time left: 01h24m45s\n",
      "epoch  31 | lr 0.000090 |lr_p 0.000090 | batch  10476 | examples/s: 105.8 | loss: 0.45191 | time elapsed: 03h47m35s | time left: 01h23m31s\n",
      "Training\n",
      "epoch  32 | lr 0.000089 |lr_p 0.000089 | batch   1072 | examples/s: 104.6 | loss: 0.48635 | time elapsed: 03h48m57s | time left: 01h22m19s\n",
      "epoch  32 | lr 0.000089 |lr_p 0.000089 | batch   3072 | examples/s: 102.0 | loss: 0.29880 | time elapsed: 03h50m17s | time left: 01h21m06s\n",
      "epoch  32 | lr 0.000089 |lr_p 0.000089 | batch   5072 | examples/s:  99.3 | loss: 0.34316 | time elapsed: 03h51m37s | time left: 01h19m52s\n",
      "epoch  32 | lr 0.000089 |lr_p 0.000089 | batch   7072 | examples/s: 103.4 | loss: 0.36289 | time elapsed: 03h52m56s | time left: 01h18m38s\n",
      "epoch  32 | lr 0.000089 |lr_p 0.000089 | batch   9072 | examples/s:  99.6 | loss: 0.31858 | time elapsed: 03h54m15s | time left: 01h17m25s\n",
      "epoch  32 | lr 0.000089 |lr_p 0.000089 | batch  11072 | examples/s:  98.9 | loss: 0.69952 | time elapsed: 03h55m35s | time left: 01h16m11s\n",
      "Training\n",
      "epoch  33 | lr 0.000088 |lr_p 0.000088 | batch   1668 | examples/s:  92.0 | loss: 0.69925 | time elapsed: 03h56m57s | time left: 01h14m58s\n",
      "epoch  33 | lr 0.000088 |lr_p 0.000088 | batch   3668 | examples/s: 101.9 | loss: 0.66058 | time elapsed: 03h58m16s | time left: 01h13m44s\n",
      "epoch  33 | lr 0.000088 |lr_p 0.000088 | batch   5668 | examples/s: 102.5 | loss: 0.37866 | time elapsed: 03h59m35s | time left: 01h12m30s\n",
      "epoch  33 | lr 0.000088 |lr_p 0.000088 | batch   7668 | examples/s: 101.2 | loss: 0.55513 | time elapsed: 04h00m54s | time left: 01h11m16s\n",
      "epoch  33 | lr 0.000088 |lr_p 0.000088 | batch   9668 | examples/s:  95.8 | loss: 0.34259 | time elapsed: 04h02m13s | time left: 01h10m02s\n",
      "Training\n",
      "epoch  34 | lr 0.000087 |lr_p 0.000087 | batch    264 | examples/s:  81.7 | loss: 0.60197 | time elapsed: 04h03m35s | time left: 01h08m48s\n",
      "epoch  34 | lr 0.000087 |lr_p 0.000087 | batch   2264 | examples/s: 104.8 | loss: 0.24841 | time elapsed: 04h04m54s | time left: 01h07m34s\n",
      "epoch  34 | lr 0.000087 |lr_p 0.000087 | batch   4264 | examples/s: 104.3 | loss: 0.34349 | time elapsed: 04h06m14s | time left: 01h06m19s\n",
      "epoch  34 | lr 0.000087 |lr_p 0.000087 | batch   6264 | examples/s: 100.3 | loss: 0.95180 | time elapsed: 04h07m33s | time left: 01h05m05s\n",
      "epoch  34 | lr 0.000087 |lr_p 0.000087 | batch   8264 | examples/s: 103.1 | loss: 0.18813 | time elapsed: 04h08m52s | time left: 01h03m51s\n",
      "epoch  34 | lr 0.000087 |lr_p 0.000087 | batch  10264 | examples/s: 101.1 | loss: 0.22310 | time elapsed: 04h10m11s | time left: 01h02m36s\n",
      "Training\n",
      "epoch  35 | lr 0.000085 |lr_p 0.000085 | batch    860 | examples/s: 101.5 | loss: 0.68612 | time elapsed: 04h11m33s | time left: 01h01m22s\n",
      "epoch  35 | lr 0.000085 |lr_p 0.000085 | batch   2860 | examples/s:  98.4 | loss: 0.34472 | time elapsed: 04h12m53s | time left: 01h00m08s\n",
      "epoch  35 | lr 0.000085 |lr_p 0.000085 | batch   4860 | examples/s:  99.5 | loss: 0.38941 | time elapsed: 04h14m13s | time left: 00h58m54s\n",
      "epoch  35 | lr 0.000085 |lr_p 0.000085 | batch   6860 | examples/s:  93.5 | loss: 0.56871 | time elapsed: 04h15m33s | time left: 00h57m39s\n",
      "epoch  35 | lr 0.000085 |lr_p 0.000085 | batch   8860 | examples/s: 104.9 | loss: 0.28711 | time elapsed: 04h16m52s | time left: 00h56m24s\n",
      "epoch  35 | lr 0.000085 |lr_p 0.000085 | batch  10860 | examples/s:  81.8 | loss: 0.62001 | time elapsed: 04h18m11s | time left: 00h55m09s\n",
      "Training\n",
      "epoch  36 | lr 0.000082 |lr_p 0.000083 | batch   1456 | examples/s:  96.0 | loss: 0.34747 | time elapsed: 04h19m33s | time left: 00h53m55s\n",
      "epoch  36 | lr 0.000082 |lr_p 0.000083 | batch   3456 | examples/s:  98.6 | loss: 0.61646 | time elapsed: 04h20m53s | time left: 00h52m41s\n",
      "epoch  36 | lr 0.000082 |lr_p 0.000083 | batch   5456 | examples/s:  99.5 | loss: 1.02825 | time elapsed: 04h22m13s | time left: 00h51m26s\n",
      "epoch  36 | lr 0.000082 |lr_p 0.000083 | batch   7456 | examples/s: 101.2 | loss: 0.28100 | time elapsed: 04h23m33s | time left: 00h50m11s\n",
      "epoch  36 | lr 0.000082 |lr_p 0.000083 | batch   9456 | examples/s:  99.0 | loss: 0.41859 | time elapsed: 04h24m53s | time left: 00h48m56s\n",
      "Training\n",
      "epoch  37 | lr 0.000080 |lr_p 0.000080 | batch     52 | examples/s: 100.2 | loss: 0.64991 | time elapsed: 04h26m15s | time left: 00h47m41s\n",
      "epoch  37 | lr 0.000080 |lr_p 0.000080 | batch   2052 | examples/s: 104.9 | loss: 0.56187 | time elapsed: 04h27m34s | time left: 00h46m26s\n",
      "epoch  37 | lr 0.000080 |lr_p 0.000080 | batch   4052 | examples/s:  98.1 | loss: 0.21505 | time elapsed: 04h28m54s | time left: 00h45m11s\n",
      "epoch  37 | lr 0.000080 |lr_p 0.000080 | batch   6052 | examples/s: 100.9 | loss: 0.24201 | time elapsed: 04h30m14s | time left: 00h43m56s\n",
      "epoch  37 | lr 0.000080 |lr_p 0.000080 | batch   8052 | examples/s:  98.8 | loss: 0.47542 | time elapsed: 04h31m32s | time left: 00h42m41s\n",
      "epoch  37 | lr 0.000080 |lr_p 0.000080 | batch  10052 | examples/s: 105.6 | loss: 0.56635 | time elapsed: 04h32m51s | time left: 00h41m26s\n",
      "Training\n",
      "epoch  38 | lr 0.000077 |lr_p 0.000078 | batch    648 | examples/s: 102.5 | loss: 0.51054 | time elapsed: 04h34m12s | time left: 00h40m11s\n",
      "epoch  38 | lr 0.000077 |lr_p 0.000078 | batch   2648 | examples/s:  94.6 | loss: 0.53858 | time elapsed: 04h35m32s | time left: 00h38m55s\n",
      "epoch  38 | lr 0.000077 |lr_p 0.000078 | batch   4648 | examples/s:  98.9 | loss: 0.59242 | time elapsed: 04h36m53s | time left: 00h37m40s\n",
      "epoch  38 | lr 0.000077 |lr_p 0.000078 | batch   6648 | examples/s: 100.6 | loss: 0.31681 | time elapsed: 04h38m13s | time left: 00h36m25s\n",
      "epoch  38 | lr 0.000077 |lr_p 0.000078 | batch   8648 | examples/s: 103.5 | loss: 0.36978 | time elapsed: 04h39m32s | time left: 00h35m09s\n",
      "epoch  38 | lr 0.000077 |lr_p 0.000078 | batch  10648 | examples/s:  99.7 | loss: 0.47957 | time elapsed: 04h40m52s | time left: 00h33m54s\n",
      "Training\n",
      "epoch  39 | lr 0.000074 |lr_p 0.000074 | batch   1244 | examples/s: 100.5 | loss: 0.48269 | time elapsed: 04h42m14s | time left: 00h32m39s\n",
      "epoch  39 | lr 0.000074 |lr_p 0.000074 | batch   3244 | examples/s: 104.4 | loss: 0.33208 | time elapsed: 04h43m33s | time left: 00h31m23s\n",
      "epoch  39 | lr 0.000074 |lr_p 0.000074 | batch   5244 | examples/s: 104.9 | loss: 0.27144 | time elapsed: 04h44m52s | time left: 00h30m08s\n",
      "epoch  39 | lr 0.000074 |lr_p 0.000074 | batch   7244 | examples/s: 105.3 | loss: 0.87697 | time elapsed: 04h46m11s | time left: 00h28m52s\n",
      "epoch  39 | lr 0.000074 |lr_p 0.000074 | batch   9244 | examples/s: 105.4 | loss: 0.44309 | time elapsed: 04h47m29s | time left: 00h27m36s\n",
      "epoch  39 | lr 0.000074 |lr_p 0.000074 | batch  11244 | examples/s: 105.1 | loss: 0.28501 | time elapsed: 04h48m50s | time left: 00h26m21s\n",
      "Training\n",
      "epoch  40 | lr 0.000070 |lr_p 0.000071 | batch   1840 | examples/s: 104.9 | loss: 1.26091 | time elapsed: 04h50m12s | time left: 00h25m05s\n",
      "epoch  40 | lr 0.000070 |lr_p 0.000071 | batch   3840 | examples/s:  94.4 | loss: 0.35300 | time elapsed: 04h51m31s | time left: 00h23m49s\n",
      "epoch  40 | lr 0.000070 |lr_p 0.000071 | batch   5840 | examples/s:  96.8 | loss: 0.38632 | time elapsed: 04h52m50s | time left: 00h22m33s\n",
      "epoch  40 | lr 0.000070 |lr_p 0.000071 | batch   7840 | examples/s: 103.5 | loss: 0.21808 | time elapsed: 04h54m09s | time left: 00h21m18s\n",
      "epoch  40 | lr 0.000070 |lr_p 0.000071 | batch   9840 | examples/s:  84.9 | loss: 0.30779 | time elapsed: 04h55m29s | time left: 00h20m02s\n",
      "Training\n",
      "epoch  41 | lr 0.000066 |lr_p 0.000068 | batch    436 | examples/s:  93.3 | loss: 0.48145 | time elapsed: 04h56m50s | time left: 00h18m46s\n",
      "epoch  41 | lr 0.000066 |lr_p 0.000068 | batch   2436 | examples/s: 100.3 | loss: 0.67462 | time elapsed: 04h58m09s | time left: 00h17m30s\n",
      "epoch  41 | lr 0.000066 |lr_p 0.000068 | batch   4436 | examples/s: 103.6 | loss: 0.62339 | time elapsed: 04h59m28s | time left: 00h16m14s\n",
      "epoch  41 | lr 0.000066 |lr_p 0.000068 | batch   6436 | examples/s: 102.3 | loss: 0.49116 | time elapsed: 05h00m47s | time left: 00h14m58s\n",
      "epoch  41 | lr 0.000066 |lr_p 0.000068 | batch   8436 | examples/s: 115.6 | loss: 0.33865 | time elapsed: 05h02m00s | time left: 00h13m42s\n",
      "epoch  41 | lr 0.000066 |lr_p 0.000068 | batch  10436 | examples/s: 114.7 | loss: 0.25293 | time elapsed: 05h03m10s | time left: 00h12m25s\n",
      "Training\n",
      "epoch  42 | lr 0.000062 |lr_p 0.000064 | batch   1032 | examples/s: 116.0 | loss: 0.40150 | time elapsed: 05h04m24s | time left: 00h11m09s\n",
      "epoch  42 | lr 0.000062 |lr_p 0.000064 | batch   3032 | examples/s: 112.3 | loss: 0.54956 | time elapsed: 05h05m37s | time left: 00h09m53s\n",
      "epoch  42 | lr 0.000062 |lr_p 0.000064 | batch   5032 | examples/s: 105.6 | loss: 0.55137 | time elapsed: 05h06m50s | time left: 00h08m37s\n",
      "epoch  42 | lr 0.000062 |lr_p 0.000064 | batch   7032 | examples/s: 114.4 | loss: 0.29713 | time elapsed: 05h08m02s | time left: 00h07m21s\n",
      "epoch  42 | lr 0.000062 |lr_p 0.000064 | batch   9032 | examples/s: 114.0 | loss: 0.45576 | time elapsed: 05h09m14s | time left: 00h06m04s\n",
      "epoch  42 | lr 0.000062 |lr_p 0.000064 | batch  11032 | examples/s: 112.6 | loss: 0.66483 | time elapsed: 05h10m26s | time left: 00h04m48s\n",
      "Training\n",
      "epoch  43 | lr 0.000058 |lr_p 0.000060 | batch   1628 | examples/s: 113.4 | loss: 0.50200 | time elapsed: 05h11m41s | time left: 00h03m32s\n",
      "epoch  43 | lr 0.000058 |lr_p 0.000060 | batch   3628 | examples/s: 102.4 | loss: 0.68082 | time elapsed: 05h12m53s | time left: 00h02m16s\n",
      "epoch  43 | lr 0.000058 |lr_p 0.000060 | batch   5628 | examples/s: 108.0 | loss: 0.57775 | time elapsed: 05h14m05s | time left: 00h01m00s\n",
      "epoch  43 | lr 0.000058 |lr_p 0.000060 | batch   7628 | examples/s: 113.8 | loss: 0.31813 | time elapsed: 05h15m17s | time left: -1h59m45s\n",
      "epoch  43 | lr 0.000058 |lr_p 0.000060 | batch   9628 | examples/s: 115.1 | loss: 0.35753 | time elapsed: 05h16m28s | time left: -1h58m29s\n",
      "Training\n",
      "epoch  44 | lr 0.000054 |lr_p 0.000056 | batch    224 | examples/s: 106.0 | loss: 0.64282 | time elapsed: 05h17m43s | time left: -1h57m13s\n",
      "epoch  44 | lr 0.000054 |lr_p 0.000056 | batch   2224 | examples/s: 113.4 | loss: 0.40013 | time elapsed: 05h18m56s | time left: -1h55m57s\n",
      "epoch  44 | lr 0.000054 |lr_p 0.000056 | batch   4224 | examples/s: 113.2 | loss: 0.71669 | time elapsed: 05h20m09s | time left: -1h54m42s\n",
      "epoch  44 | lr 0.000054 |lr_p 0.000056 | batch   6224 | examples/s: 110.8 | loss: 0.43887 | time elapsed: 05h21m21s | time left: -1h53m26s\n",
      "epoch  44 | lr 0.000054 |lr_p 0.000056 | batch   8224 | examples/s: 114.6 | loss: 0.67291 | time elapsed: 05h22m33s | time left: -1h52m10s\n",
      "epoch  44 | lr 0.000054 |lr_p 0.000056 | batch  10224 | examples/s: 113.1 | loss: 0.46929 | time elapsed: 05h23m45s | time left: -1h50m54s\n",
      "Training\n",
      "epoch  45 | lr 0.000050 |lr_p 0.000052 | batch    820 | examples/s: 101.8 | loss: 0.32622 | time elapsed: 05h25m00s | time left: -1h49m38s\n",
      "epoch  45 | lr 0.000050 |lr_p 0.000052 | batch   2820 | examples/s: 105.3 | loss: 0.63897 | time elapsed: 05h26m13s | time left: -1h48m23s\n",
      "epoch  45 | lr 0.000050 |lr_p 0.000052 | batch   4820 | examples/s: 113.9 | loss: 0.39574 | time elapsed: 05h27m25s | time left: -1h47m07s\n",
      "epoch  45 | lr 0.000050 |lr_p 0.000052 | batch   6820 | examples/s: 117.0 | loss: 0.33405 | time elapsed: 05h28m37s | time left: -1h45m51s\n",
      "epoch  45 | lr 0.000050 |lr_p 0.000052 | batch   8820 | examples/s: 110.3 | loss: 0.86956 | time elapsed: 05h29m49s | time left: -1h44m35s\n",
      "epoch  45 | lr 0.000050 |lr_p 0.000052 | batch  10820 | examples/s: 110.9 | loss: 0.64461 | time elapsed: 05h31m01s | time left: -1h43m20s\n",
      "Training\n",
      "epoch  46 | lr 0.000045 |lr_p 0.000048 | batch   1416 | examples/s: 116.4 | loss: 0.38747 | time elapsed: 05h32m16s | time left: -1h42m04s\n",
      "epoch  46 | lr 0.000045 |lr_p 0.000048 | batch   3416 | examples/s: 106.4 | loss: 0.24114 | time elapsed: 05h33m28s | time left: -1h40m48s\n",
      "epoch  46 | lr 0.000045 |lr_p 0.000048 | batch   5416 | examples/s: 113.2 | loss: 0.68167 | time elapsed: 05h34m41s | time left: -1h39m33s\n",
      "epoch  46 | lr 0.000045 |lr_p 0.000048 | batch   7416 | examples/s: 117.3 | loss: 0.28477 | time elapsed: 05h35m53s | time left: -1h38m17s\n",
      "epoch  46 | lr 0.000045 |lr_p 0.000048 | batch   9416 | examples/s: 113.6 | loss: 0.43869 | time elapsed: 05h37m05s | time left: -1h37m02s\n",
      "Training\n",
      "epoch  47 | lr 0.000041 |lr_p 0.000044 | batch     12 | examples/s: 103.2 | loss: 0.27357 | time elapsed: 05h38m20s | time left: -1h35m46s\n",
      "epoch  47 | lr 0.000041 |lr_p 0.000044 | batch   2012 | examples/s: 109.0 | loss: 0.32599 | time elapsed: 05h39m33s | time left: -1h34m31s\n",
      "epoch  47 | lr 0.000041 |lr_p 0.000044 | batch   4012 | examples/s: 115.9 | loss: 0.54442 | time elapsed: 05h40m45s | time left: -1h33m15s\n",
      "epoch  47 | lr 0.000041 |lr_p 0.000044 | batch   6012 | examples/s: 116.0 | loss: 0.41749 | time elapsed: 05h41m57s | time left: -1h32m00s\n",
      "epoch  47 | lr 0.000041 |lr_p 0.000044 | batch   8012 | examples/s: 115.4 | loss: 0.56326 | time elapsed: 05h43m09s | time left: -1h30m44s\n",
      "epoch  47 | lr 0.000041 |lr_p 0.000044 | batch  10012 | examples/s: 109.6 | loss: 0.22976 | time elapsed: 05h44m21s | time left: -1h29m29s\n",
      "Training\n",
      "epoch  48 | lr 0.000037 |lr_p 0.000040 | batch    608 | examples/s: 116.7 | loss: 0.30489 | time elapsed: 05h45m35s | time left: -1h28m13s\n",
      "epoch  48 | lr 0.000037 |lr_p 0.000040 | batch   2608 | examples/s: 112.8 | loss: 0.28081 | time elapsed: 05h46m48s | time left: -1h26m58s\n",
      "epoch  48 | lr 0.000037 |lr_p 0.000040 | batch   4608 | examples/s: 112.4 | loss: 0.30178 | time elapsed: 05h47m59s | time left: -1h25m43s\n",
      "epoch  48 | lr 0.000037 |lr_p 0.000040 | batch   6608 | examples/s: 100.4 | loss: 0.49426 | time elapsed: 05h49m12s | time left: -1h24m27s\n",
      "epoch  48 | lr 0.000037 |lr_p 0.000040 | batch   8608 | examples/s: 114.6 | loss: 0.27966 | time elapsed: 05h50m23s | time left: -1h23m12s\n",
      "epoch  48 | lr 0.000037 |lr_p 0.000040 | batch  10608 | examples/s: 111.1 | loss: 0.22168 | time elapsed: 05h51m35s | time left: -1h21m57s\n",
      "Training\n",
      "epoch  49 | lr 0.000033 |lr_p 0.000036 | batch   1204 | examples/s: 104.9 | loss: 0.47220 | time elapsed: 05h52m49s | time left: -1h20m42s\n",
      "epoch  49 | lr 0.000033 |lr_p 0.000036 | batch   3204 | examples/s: 109.3 | loss: 0.79936 | time elapsed: 05h54m02s | time left: -1h19m26s\n",
      "epoch  49 | lr 0.000033 |lr_p 0.000036 | batch   5204 | examples/s: 111.9 | loss: 0.21000 | time elapsed: 05h55m14s | time left: -1h18m11s\n",
      "epoch  49 | lr 0.000033 |lr_p 0.000036 | batch   7204 | examples/s: 106.9 | loss: 0.38305 | time elapsed: 05h56m26s | time left: -1h16m56s\n",
      "epoch  49 | lr 0.000033 |lr_p 0.000036 | batch   9204 | examples/s: 107.0 | loss: 0.31274 | time elapsed: 05h57m38s | time left: -1h15m41s\n",
      "epoch  49 | lr 0.000033 |lr_p 0.000036 | batch  11204 | examples/s: 113.4 | loss: 0.47945 | time elapsed: 05h58m50s | time left: -1h14m26s\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "from options import LiteMonoOptions\n",
    "from trainer import Trainer\n",
    "\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import json\n",
    "\n",
    "from utils import *\n",
    "from kitti_utils import *\n",
    "from layers import *\n",
    "\n",
    "import datasets\n",
    "import networks\n",
    "from linear_warmup_cosine_annealing_warm_restarts_weight_decay import ChainedScheduler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure as SSIM\n",
    "from torchmetrics.regression import MeanSquaredError as MSE\n",
    "from torchmetrics.collections import MetricCollection\n",
    "import gc\n",
    "from torchvision.transforms import Normalize\n",
    "\n",
    "\n",
    "def time_sync():\n",
    "    # PyTorch-accurate time\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    return time.time()\n",
    "\n",
    "sample_tfms = [\n",
    "    A.HorizontalFlip(),\n",
    "    A.GaussNoise(p=0.2),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(p=.3),\n",
    "        A.MedianBlur(blur_limit=3, p=0.3),\n",
    "        A.Blur(blur_limit=3, p=0.5),\n",
    "    ], p=0.3),\n",
    "    A.RGBShift(),\n",
    "    A.RandomBrightnessContrast(),\n",
    "    A.RandomResizedCrop(384,384),\n",
    "    A.ColorJitter(),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.3, rotate_limit=45, p=0.5),\n",
    "    A.HueSaturationValue(p=0.3),\n",
    "]\n",
    "train_tfms = A.Compose([\n",
    "    *sample_tfms,\n",
    "    A.Resize(224,224),\n",
    "    A.Normalize(always_apply=True),\n",
    "    ToTensorV2()\n",
    "])\n",
    "valid_tfms = A.Compose([\n",
    "    A.Resize(224,224),\n",
    "    A.Normalize(always_apply=True),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self,df,tfms):\n",
    "        self.df = df\n",
    "        self.tfms=tfms\n",
    "    def open_im(self,p,gray=False):\n",
    "        im = cv.imread(str(p))\n",
    "        im = cv.cvtColor(im,cv.COLOR_BGR2GRAY if gray else cv.COLOR_BGR2RGB)\n",
    "        return im\n",
    "    \n",
    "    def __len__(self,):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        s = self.df.iloc[idx,:]\n",
    "        im, dp = s[0],s[1]\n",
    "        im, dp = self.open_im(im), self.open_im(dp,True)\n",
    "        augs = self.tfms(image=im,mask=dp)\n",
    "        im, dp = augs['image'], augs['mask'] / 255.\n",
    "        return im, dp.unsqueeze(0)\n",
    "\n",
    "train_csv = Path('./nyu-depth-v2/nyu_data/data/nyu2_train.csv')\n",
    "train_ims_path = Path('./nyu-depth-v2/nyu_data/data/nyu2_train')\n",
    "base_path = Path('./nyu-depth-v2/nyu_data')\n",
    "\n",
    "df = pd.read_csv(train_csv,header=None)\n",
    "df[0] = df[0].map(lambda x:base_path/x)\n",
    "df[1] = df[1].map(lambda x:base_path/x)\n",
    "df.head()\n",
    "    \n",
    "train_df, val_df = train_test_split(df,test_size=0.1,shuffle=True)\n",
    "val_df, test_df = train_test_split(val_df, test_size=0.1,shuffle=True)\n",
    "train_df.reset_index(drop=True,inplace=True)\n",
    "val_df.reset_index(drop=True,inplace=True)\n",
    "test_df.reset_index(drop=True,inplace=True)\n",
    "len(train_df),len(val_df), len(test_df)\n",
    "\n",
    "train_ds = Dataset(train_df,train_tfms)\n",
    "val_ds = Dataset(val_df,valid_tfms)\n",
    "test_ds = Dataset(test_df, valid_tfms)\n",
    "len(train_ds), len(val_ds), len(test_ds)\n",
    "\n",
    "fn_loss = nn.MSELoss()\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, options):\n",
    "        self.opt = options\n",
    "        self.log_path = os.path.join(self.opt.log_dir, self.opt.model_name)\n",
    "\n",
    "        # checking height and width are multiples of 32\n",
    "        assert self.opt.height % 32 == 0, \"'height' must be a multiple of 32\"\n",
    "        assert self.opt.width % 32 == 0, \"'width' must be a multiple of 32\"\n",
    "\n",
    "        self.models = {}\n",
    "        self.models_pose = {}\n",
    "        self.parameters_to_train = []\n",
    "        self.parameters_to_train_pose = []\n",
    "\n",
    "        self.device = torch.device(\"cpu\" if self.opt.no_cuda else \"cuda\")\n",
    "        self.profile = self.opt.profile\n",
    "\n",
    "        self.num_scales = len(self.opt.scales)\n",
    "        self.frame_ids = len(self.opt.frame_ids)\n",
    "        self.num_pose_frames = 2 if self.opt.pose_model_input == \"pairs\" else self.num_input_frames\n",
    "\n",
    "        assert self.opt.frame_ids[0] == 0, \"frame_ids must start with 0\"\n",
    "\n",
    "        self.use_pose_net = not (self.opt.use_stereo and self.opt.frame_ids == [0])\n",
    "\n",
    "        if self.opt.use_stereo:\n",
    "            self.opt.frame_ids.append(\"s\")\n",
    "\n",
    "        self.models[\"encoder\"] = networks.LiteMono(model=self.opt.model,\n",
    "                                                   drop_path_rate=self.opt.drop_path,\n",
    "                                                   width=self.opt.width, height=self.opt.height)\n",
    "\n",
    "        self.models[\"encoder\"].to(self.device)\n",
    "        self.parameters_to_train += list(self.models[\"encoder\"].parameters())\n",
    "\n",
    "        self.models[\"depth\"] = networks.DepthDecoder(self.models[\"encoder\"].num_ch_enc,\n",
    "                                                     self.opt.scales)\n",
    "        self.models[\"depth\"].to(self.device)\n",
    "        self.parameters_to_train += list(self.models[\"depth\"].parameters())\n",
    "\n",
    "        if self.use_pose_net:\n",
    "            if self.opt.pose_model_type == \"separate_resnet\":\n",
    "                self.models_pose[\"pose_encoder\"] = networks.ResnetEncoder(\n",
    "                    self.opt.num_layers,\n",
    "                    self.opt.weights_init == \"pretrained\",\n",
    "                    num_input_images=self.num_pose_frames)\n",
    "\n",
    "                self.models_pose[\"pose_encoder\"].to(self.device)\n",
    "                self.parameters_to_train_pose += list(self.models_pose[\"pose_encoder\"].parameters())\n",
    "\n",
    "                self.models_pose[\"pose\"] = networks.PoseDecoder(\n",
    "                    self.models_pose[\"pose_encoder\"].num_ch_enc,\n",
    "                    num_input_features=1,\n",
    "                    num_frames_to_predict_for=2)\n",
    "\n",
    "            elif self.opt.pose_model_type == \"shared\":\n",
    "                self.models_pose[\"pose\"] = networks.PoseDecoder(\n",
    "                    self.models[\"encoder\"].num_ch_enc, self.num_pose_frames)\n",
    "\n",
    "            elif self.opt.pose_model_type == \"posecnn\":\n",
    "                self.models_pose[\"pose\"] = networks.PoseCNN(\n",
    "                    self.num_input_frames if self.opt.pose_model_input == \"all\" else 2)\n",
    "\n",
    "            self.models_pose[\"pose\"].to(self.device)\n",
    "            self.parameters_to_train_pose += list(self.models_pose[\"pose\"].parameters())\n",
    "\n",
    "        if self.opt.predictive_mask:\n",
    "            assert self.opt.disable_automasking, \\\n",
    "                \"When using predictive_mask, please disable automasking with --disable_automasking\"\n",
    "\n",
    "            # Our implementation of the predictive masking baseline has the the same architecture\n",
    "            # as our depth decoder. We predict a separate mask for each source frame.\n",
    "            self.models[\"predictive_mask\"] = networks.DepthDecoder(\n",
    "                self.models[\"encoder\"].num_ch_enc, self.opt.scales,\n",
    "                num_output_channels=(len(self.opt.frame_ids) - 1))\n",
    "            self.models[\"predictive_mask\"].to(self.device)\n",
    "            self.parameters_to_train += list(self.models[\"predictive_mask\"].parameters())\n",
    "\n",
    "        self.model_optimizer = optim.AdamW(self.parameters_to_train, self.opt.lr[0], weight_decay=self.opt.weight_decay)\n",
    "        if self.use_pose_net:\n",
    "            self.model_pose_optimizer = optim.AdamW(self.parameters_to_train_pose, self.opt.lr[3], weight_decay=self.opt.weight_decay)\n",
    "\n",
    "        self.model_lr_scheduler = ChainedScheduler(\n",
    "                            self.model_optimizer,\n",
    "                            T_0=int(self.opt.lr[2]),\n",
    "                            T_mul=1,\n",
    "                            eta_min=self.opt.lr[1],\n",
    "                            last_epoch=-1,\n",
    "                            max_lr=self.opt.lr[0],\n",
    "                            warmup_steps=0,\n",
    "                            gamma=0.9\n",
    "                        )\n",
    "        self.model_pose_lr_scheduler = ChainedScheduler(\n",
    "            self.model_pose_optimizer,\n",
    "            T_0=int(self.opt.lr[5]),\n",
    "            T_mul=1,\n",
    "            eta_min=self.opt.lr[4],\n",
    "            last_epoch=-1,\n",
    "            max_lr=self.opt.lr[3],\n",
    "            warmup_steps=0,\n",
    "            gamma=0.9\n",
    "        )\n",
    "\n",
    "        if self.opt.load_weights_folder is not None:\n",
    "            self.load_model()\n",
    "\n",
    "        if self.opt.mypretrain is not None:\n",
    "            self.load_pretrain()\n",
    "\n",
    "\n",
    "        # data\n",
    "        datasets_dict = {\"kitti\": datasets.KITTIRAWDataset,\n",
    "                         \"kitti_odom\": datasets.KITTIOdomDataset}\n",
    "        self.dataset = datasets_dict[self.opt.dataset]\n",
    "\n",
    "        fpath = os.path.join(par_dir, \"splits\", self.opt.split, \"{}_files.txt\")\n",
    "\n",
    "        train_filenames = readlines(fpath.format(\"train\"))\n",
    "        val_filenames = readlines(fpath.format(\"val\"))\n",
    "        img_ext = '.png' if self.opt.png else '.jpg'\n",
    "\n",
    "        num_train_samples = len(train_filenames)\n",
    "        self.num_total_steps = num_train_samples // self.opt.batch_size * self.opt.num_epochs\n",
    "        ################\n",
    "        train_dataset = train_ds\n",
    "        #self.dataset(\n",
    "            # self.opt.data_path, train_filenames, self.opt.height, self.opt.width,\n",
    "            # self.opt.frame_ids, 4, is_train=True, img_ext=img_ext)\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset, self.opt.batch_size, True,\n",
    "            num_workers=self.opt.num_workers, pin_memory=True, drop_last=True)\n",
    "        val_dataset = val_ds \n",
    "        # self.dataset(\n",
    "        #     self.opt.data_path, val_filenames, self.opt.height, self.opt.width,\n",
    "        #     self.opt.frame_ids, 4, is_train=False, img_ext=img_ext)\n",
    "        self.val_loader = DataLoader(\n",
    "            val_dataset, self.opt.batch_size, True,\n",
    "            num_workers=self.opt.num_workers, pin_memory=True, drop_last=True)\n",
    "        self.val_iter = iter(self.val_loader)\n",
    "\n",
    "        self.writers = {}\n",
    "        for mode in [\"train\", \"val\"]:\n",
    "            self.writers[mode] = SummaryWriter(os.path.join(self.log_path, mode))\n",
    "\n",
    "        if not self.opt.no_ssim:\n",
    "            self.ssim = SSIM()\n",
    "            self.ssim.to(self.device)\n",
    "\n",
    "        self.backproject_depth = {}\n",
    "        self.project_3d = {}\n",
    "        for scale in self.opt.scales:\n",
    "            h = self.opt.height // (2 ** scale)\n",
    "            w = self.opt.width // (2 ** scale)\n",
    "\n",
    "            self.backproject_depth[scale] = BackprojectDepth(self.opt.batch_size, h, w)\n",
    "            self.backproject_depth[scale].to(self.device)\n",
    "\n",
    "            self.project_3d[scale] = Project3D(self.opt.batch_size, h, w)\n",
    "            self.project_3d[scale].to(self.device)\n",
    "\n",
    "        self.depth_metric_names = [\n",
    "            \"de/abs_rel\", \"de/sq_rel\", \"de/rms\", \"de/log_rms\", \"da/a1\", \"da/a2\", \"da/a3\"]\n",
    "\n",
    "        print(\"There are {:d} training items and {:d} validation items\\n\".format(\n",
    "            len(train_dataset), len(val_dataset)))\n",
    "\n",
    "        self.save_opts()\n",
    "\n",
    "    def set_train(self):\n",
    "        \"\"\"Convert all models to training mode\n",
    "        \"\"\"\n",
    "        for m in self.models.values():\n",
    "            m.train()\n",
    "\n",
    "    def set_eval(self):\n",
    "        \"\"\"Convert all models to testing/evaluation mode\n",
    "        \"\"\"\n",
    "        for m in self.models.values():\n",
    "            m.eval()\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Run the entire training pipeline\n",
    "        \"\"\"\n",
    "        self.epoch = 0\n",
    "        self.step = 0\n",
    "        self.start_time = time.time()\n",
    "        for self.epoch in range(self.opt.num_epochs):\n",
    "            self.run_epoch()\n",
    "            if (self.epoch + 1) % self.opt.save_frequency == 0:\n",
    "                self.save_model()\n",
    "\n",
    "    def run_epoch(self):\n",
    "        \"\"\"Run a single epoch of training and validation\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Training\")\n",
    "        self.set_train()\n",
    "\n",
    "        self.model_lr_scheduler.step()\n",
    "        if self.use_pose_net:\n",
    "            self.model_pose_lr_scheduler.step()\n",
    "\n",
    "        for batch_idx, inputs in enumerate(self.train_loader):\n",
    "\n",
    "            before_op_time = time.time()\n",
    "\n",
    "            outputs, losses = self.process_batch(inputs)\n",
    "\n",
    "            # self.model_optimizer.zero_grad()\n",
    "            # if self.use_pose_net:\n",
    "            #     self.model_pose_optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            self.model_optimizer.step()\n",
    "            # if self.use_pose_net:\n",
    "            #     self.model_pose_optimizer.step()\n",
    "\n",
    "            duration = time.time() - before_op_time\n",
    "\n",
    "            # log less frequently after the first 2000 steps to save time & disk space\n",
    "            early_phase = batch_idx % self.opt.log_frequency == 0 and self.step < 20000\n",
    "            late_phase = self.step % 2000 == 0\n",
    "\n",
    "            if early_phase or late_phase:\n",
    "                self.log_time(batch_idx, duration, losses.cpu().data)\n",
    "\n",
    "                # if \"depth_gt\" in inputs:\n",
    "                #     self.compute_depth_losses(inputs, outputs, losses)\n",
    "\n",
    "                # self.log(\"train\", inputs, outputs, losses)\n",
    "                self.val()\n",
    "\n",
    "            self.step += 1\n",
    "\n",
    "    def process_batch(self, inputs):\n",
    "        \"\"\"Pass a minibatch through the network and generate images and losses\n",
    "        \"\"\"\n",
    "        losses = 0.\n",
    "        # print(inputs[0].shape, inputs[1].shape, len(inputs))\n",
    "        for key, ipt in enumerate(inputs):\n",
    "            inputs[key] = ipt.to(self.device)\n",
    "\n",
    "#         if self.opt.pose_model_type == \"shared\":\n",
    "#             # If we are using a shared encoder for both depth and pose (as advocated\n",
    "#             # in monodepthv1), then all images are fed separately through the depth encoder.\n",
    "#             all_color_aug = torch.cat([inputs[(\"color_aug\", i, 0)] for i in self.opt.frame_ids])\n",
    "#             all_features = self.models[\"encoder\"](all_color_aug)\n",
    "#             all_features = [torch.split(f, self.opt.batch_size) for f in all_features]\n",
    "\n",
    "#             features = {}\n",
    "#             for i, k in enumerate(self.opt.frame_ids):\n",
    "#                 features[k] = [f[i] for f in all_features]\n",
    "\n",
    "#             outputs = self.models[\"depth\"](features[0])\n",
    "#         else:\n",
    "#             # Otherwise, we only feed the image with frame_id 0 through the depth encoder\n",
    "\n",
    "        features = self.models[\"encoder\"](inputs[0])#[\"color_aug\", 0, 0]\n",
    "\n",
    "        outputs = self.models[\"depth\"](features)\n",
    "\n",
    "        # if self.opt.predictive_mask:\n",
    "        #     outputs[\"predictive_mask\"] = self.models[\"predictive_mask\"](features)\n",
    "\n",
    "        # if self.use_pose_net:\n",
    "        #     outputs.update(self.predict_poses(inputs, features))\n",
    "\n",
    "        # self.generate_images_pred(inputs[0], outputs)\n",
    "        # print(outputs.keys())\n",
    "        # print(list(outputs.values())[-1].shape)\n",
    "        # print(list(outputs.values())[-1])\n",
    "        # losses = self.compute_losses(inputs[1], list(outputs.values())[-1])\n",
    "        gts = inputs[1]\n",
    "        prds = list(outputs.values())[-1]\n",
    "        for prd, gt in zip(gts, prds):\n",
    "            loss = fn_loss(gts, prds)\n",
    "            losses += loss\n",
    "        # losses = nn.MSELoss(inputs[1], list(outputs.values())[-1])\n",
    "\n",
    "        return outputs, losses\n",
    "\n",
    "    def predict_poses(self, inputs, features):\n",
    "        \"\"\"Predict poses between input frames for monocular sequences.\n",
    "        \"\"\"\n",
    "        outputs = {}\n",
    "        if self.num_pose_frames == 2:\n",
    "            # In this setting, we compute the pose to each source frame via a\n",
    "            # separate forward pass through the pose network.\n",
    "\n",
    "            # select what features the pose network takes as input\n",
    "            if self.opt.pose_model_type == \"shared\":\n",
    "                pose_feats = {f_i: features[f_i] for f_i in self.opt.frame_ids}\n",
    "            else:\n",
    "                pose_feats = {f_i: inputs[\"color_aug\", f_i, 0] for f_i in self.opt.frame_ids}\n",
    "\n",
    "            for f_i in self.opt.frame_ids[1:]:\n",
    "                if f_i != \"s\":\n",
    "                    # To maintain ordering we always pass frames in temporal order\n",
    "                    if f_i < 0:\n",
    "                        pose_inputs = [pose_feats[f_i], pose_feats[0]]\n",
    "                    else:\n",
    "                        pose_inputs = [pose_feats[0], pose_feats[f_i]]\n",
    "\n",
    "                    if self.opt.pose_model_type == \"separate_resnet\":\n",
    "                        pose_inputs = [self.models_pose[\"pose_encoder\"](torch.cat(pose_inputs, 1))]\n",
    "                    elif self.opt.pose_model_type == \"posecnn\":\n",
    "                        pose_inputs = torch.cat(pose_inputs, 1)\n",
    "\n",
    "                    axisangle, translation = self.models_pose[\"pose\"](pose_inputs)\n",
    "                    outputs[(\"axisangle\", 0, f_i)] = axisangle\n",
    "                    outputs[(\"translation\", 0, f_i)] = translation\n",
    "\n",
    "                    # Invert the matrix if the frame id is negative\n",
    "                    outputs[(\"cam_T_cam\", 0, f_i)] = transformation_from_parameters(\n",
    "                        axisangle[:, 0], translation[:, 0], invert=(f_i < 0))\n",
    "\n",
    "        else:\n",
    "            # Here we input all frames to the pose net (and predict all poses) together\n",
    "            if self.opt.pose_model_type in [\"separate_resnet\", \"posecnn\"]:\n",
    "                pose_inputs = torch.cat(\n",
    "                    [inputs[(\"color_aug\", i, 0)] for i in self.opt.frame_ids if i != \"s\"], 1)\n",
    "\n",
    "                if self.opt.pose_model_type == \"separate_resnet\":\n",
    "                    pose_inputs = [self.models[\"pose_encoder\"](pose_inputs)]\n",
    "\n",
    "            elif self.opt.pose_model_type == \"shared\":\n",
    "                pose_inputs = [features[i] for i in self.opt.frame_ids if i != \"s\"]\n",
    "\n",
    "            axisangle, translation = self.models_pose[\"pose\"](pose_inputs)\n",
    "\n",
    "            for i, f_i in enumerate(self.opt.frame_ids[1:]):\n",
    "                if f_i != \"s\":\n",
    "                    outputs[(\"axisangle\", 0, f_i)] = axisangle\n",
    "                    outputs[(\"translation\", 0, f_i)] = translation\n",
    "                    outputs[(\"cam_T_cam\", 0, f_i)] = transformation_from_parameters(\n",
    "                        axisangle[:, i], translation[:, i])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def val(self):\n",
    "        \"\"\"Validate the model on a single minibatch\n",
    "        \"\"\"\n",
    "        self.set_eval()\n",
    "        try:\n",
    "            inputs = self.val_iter.next()\n",
    "        except StopIteration:\n",
    "            self.val_iter = iter(self.val_loader)\n",
    "            inputs = self.val_iter.next()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs, losses = self.process_batch(inputs)\n",
    "\n",
    "            if \"depth_gt\" in inputs:\n",
    "                self.compute_depth_losses(inputs, outputs, losses)\n",
    "\n",
    "            # self.log(\"val\", inputs, outputs, losses)\n",
    "            del inputs, outputs, losses\n",
    "\n",
    "        self.set_train()\n",
    "\n",
    "    def generate_images_pred(self, inputs, outputs):\n",
    "        \"\"\"Generate the warped (reprojected) color images for a minibatch.\n",
    "        Generated images are saved into the `outputs` dictionary.\n",
    "        \"\"\"\n",
    "        for scale in self.opt.scales:\n",
    "            disp = outputs[(\"disp\", scale)]\n",
    "            if self.opt.v1_multiscale:\n",
    "                source_scale = scale\n",
    "            else:\n",
    "                disp = F.interpolate(\n",
    "                    disp, [self.opt.height, self.opt.width], mode=\"bilinear\", align_corners=False)\n",
    "                source_scale = 0\n",
    "\n",
    "            _, depth = disp_to_depth(disp, self.opt.min_depth, self.opt.max_depth)\n",
    "\n",
    "            outputs[(\"depth\", 0, scale)] = depth\n",
    "\n",
    "            for i, frame_id in enumerate(self.opt.frame_ids[1:]):\n",
    "\n",
    "                if frame_id == \"s\":\n",
    "                    T = inputs[\"stereo_T\"]\n",
    "                else:\n",
    "                    T = outputs[(\"cam_T_cam\", 0, frame_id)]\n",
    "\n",
    "                # from the authors of https://arxiv.org/abs/1712.00175\n",
    "                if self.opt.pose_model_type == \"posecnn\":\n",
    "\n",
    "                    axisangle = outputs[(\"axisangle\", 0, frame_id)]\n",
    "                    translation = outputs[(\"translation\", 0, frame_id)]\n",
    "\n",
    "                    inv_depth = 1 / depth\n",
    "                    mean_inv_depth = inv_depth.mean(3, True).mean(2, True)\n",
    "\n",
    "                    T = transformation_from_parameters(\n",
    "                        axisangle[:, 0], translation[:, 0] * mean_inv_depth[:, 0], frame_id < 0)\n",
    "\n",
    "                cam_points = self.backproject_depth[source_scale](\n",
    "                    depth, inputs[(\"inv_K\", source_scale)])\n",
    "                pix_coords = self.project_3d[source_scale](\n",
    "                    cam_points, inputs[(\"K\", source_scale)], T)\n",
    "\n",
    "                outputs[(\"sample\", frame_id, scale)] = pix_coords\n",
    "\n",
    "                outputs[(\"color\", frame_id, scale)] = F.grid_sample(\n",
    "                    inputs[(\"color\", frame_id, source_scale)],\n",
    "                    outputs[(\"sample\", frame_id, scale)],\n",
    "                    padding_mode=\"border\", align_corners=True)\n",
    "\n",
    "                if not self.opt.disable_automasking:\n",
    "                    outputs[(\"color_identity\", frame_id, scale)] = \\\n",
    "                        inputs[(\"color\", frame_id, source_scale)]\n",
    "\n",
    "    def compute_reprojection_loss(self, pred, target):\n",
    "        \"\"\"Computes reprojection loss between a batch of predicted and target images\n",
    "        \"\"\"\n",
    "        abs_diff = torch.abs(target - pred)\n",
    "        l1_loss = abs_diff.mean(1, True)\n",
    "\n",
    "        if self.opt.no_ssim:\n",
    "            reprojection_loss = l1_loss\n",
    "        else:\n",
    "            ssim_loss = self.ssim(pred, target).mean(1, True)\n",
    "            reprojection_loss = 0.85 * ssim_loss + 0.15 * l1_loss\n",
    "\n",
    "        return reprojection_loss\n",
    "\n",
    "    def compute_losses(self, inputs, outputs):\n",
    "        \"\"\"Compute the reprojection and smoothness losses for a minibatch\n",
    "        \"\"\"\n",
    "\n",
    "        losses = {}\n",
    "        total_loss = 0\n",
    "\n",
    "        for scale in self.opt.scales:\n",
    "            loss = 0\n",
    "            reprojection_losses = []\n",
    "\n",
    "            if self.opt.v1_multiscale:\n",
    "                source_scale = scale\n",
    "            else:\n",
    "                source_scale = 0\n",
    "\n",
    "            disp = outputs[(\"disp\", scale)]\n",
    "            color = inputs[(\"color\", 0, scale)]\n",
    "            target = inputs[(\"color\", 0, source_scale)]\n",
    "\n",
    "            for frame_id in self.opt.frame_ids[1:]:\n",
    "                pred = outputs[(\"color\", frame_id, scale)]\n",
    "                reprojection_losses.append(self.compute_reprojection_loss(pred, target))\n",
    "\n",
    "            reprojection_losses = torch.cat(reprojection_losses, 1)\n",
    "\n",
    "            if not self.opt.disable_automasking:\n",
    "                identity_reprojection_losses = []\n",
    "                for frame_id in self.opt.frame_ids[1:]:\n",
    "                    pred = inputs[(\"color\", frame_id, source_scale)]\n",
    "                    identity_reprojection_losses.append(\n",
    "                        self.compute_reprojection_loss(pred, target))\n",
    "\n",
    "                identity_reprojection_losses = torch.cat(identity_reprojection_losses, 1)\n",
    "\n",
    "                if self.opt.avg_reprojection:\n",
    "                    identity_reprojection_loss = identity_reprojection_losses.mean(1, keepdim=True)\n",
    "                else:\n",
    "                    # save both images, and do min all at once below\n",
    "                    identity_reprojection_loss = identity_reprojection_losses\n",
    "\n",
    "            elif self.opt.predictive_mask:\n",
    "                # use the predicted mask\n",
    "                mask = outputs[\"predictive_mask\"][\"disp\", scale]\n",
    "                if not self.opt.v1_multiscale:\n",
    "                    mask = F.interpolate(\n",
    "                        mask, [self.opt.height, self.opt.width],\n",
    "                        mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "                reprojection_losses *= mask\n",
    "\n",
    "                # add a loss pushing mask to 1 (using nn.BCELoss for stability)\n",
    "                weighting_loss = 0.2 * nn.BCELoss()(mask, torch.ones(mask.shape).cuda())\n",
    "                loss += weighting_loss.mean()\n",
    "\n",
    "            if self.opt.avg_reprojection:\n",
    "                reprojection_loss = reprojection_losses.mean(1, keepdim=True)\n",
    "            else:\n",
    "                reprojection_loss = reprojection_losses\n",
    "\n",
    "            if not self.opt.disable_automasking:\n",
    "                # add random numbers to break ties\n",
    "                identity_reprojection_loss += torch.randn(\n",
    "                    identity_reprojection_loss.shape, device=self.device) * 0.00001\n",
    "\n",
    "                combined = torch.cat((identity_reprojection_loss, reprojection_loss), dim=1)\n",
    "            else:\n",
    "                combined = reprojection_loss\n",
    "\n",
    "            if combined.shape[1] == 1:\n",
    "                to_optimise = combined\n",
    "            else:\n",
    "                to_optimise, idxs = torch.min(combined, dim=1)\n",
    "\n",
    "            if not self.opt.disable_automasking:\n",
    "                outputs[\"identity_selection/{}\".format(scale)] = (\n",
    "                    idxs > identity_reprojection_loss.shape[1] - 1).float()\n",
    "\n",
    "            loss += to_optimise.mean()\n",
    "\n",
    "            mean_disp = disp.mean(2, True).mean(3, True)\n",
    "            norm_disp = disp / (mean_disp + 1e-7)\n",
    "            smooth_loss = get_smooth_loss(norm_disp, color)\n",
    "\n",
    "            loss += self.opt.disparity_smoothness * smooth_loss / (2 ** scale)\n",
    "            total_loss += loss\n",
    "            losses[\"loss/{}\".format(scale)] = loss\n",
    "\n",
    "        total_loss /= self.num_scales\n",
    "        losses[\"loss\"] = total_loss\n",
    "        return losses\n",
    "\n",
    "    def compute_depth_losses(self, inputs, outputs, losses):\n",
    "        \"\"\"Compute depth metrics, to allow monitoring during training\n",
    "\n",
    "        This isn't particularly accurate as it averages over the entire batch,\n",
    "        so is only used to give an indication of validation performance\n",
    "        \"\"\"\n",
    "        depth_pred = outputs[(\"depth\", 0, 0)]\n",
    "        depth_pred = torch.clamp(F.interpolate(\n",
    "            depth_pred, [375, 1242], mode=\"bilinear\", align_corners=False), 1e-3, 80)\n",
    "        depth_pred = depth_pred.detach()\n",
    "\n",
    "        depth_gt = inputs[\"depth_gt\"]\n",
    "        mask = depth_gt > 0\n",
    "\n",
    "        # garg/eigen crop\n",
    "        crop_mask = torch.zeros_like(mask)\n",
    "        crop_mask[:, :, 153:371, 44:1197] = 1\n",
    "        mask = mask * crop_mask\n",
    "\n",
    "        depth_gt = depth_gt[mask]\n",
    "        depth_pred = depth_pred[mask]\n",
    "        depth_pred *= torch.median(depth_gt) / torch.median(depth_pred)\n",
    "\n",
    "        depth_pred = torch.clamp(depth_pred, min=1e-3, max=80)\n",
    "\n",
    "        depth_errors = compute_depth_errors(depth_gt, depth_pred)\n",
    "\n",
    "        for i, metric in enumerate(self.depth_metric_names):\n",
    "            losses[metric] = np.array(depth_errors[i].cpu())\n",
    "\n",
    "    def log_time(self, batch_idx, duration, loss):\n",
    "        \"\"\"Print a logging statement to the terminal\n",
    "        \"\"\"\n",
    "        samples_per_sec = self.opt.batch_size / duration\n",
    "        time_sofar = time.time() - self.start_time\n",
    "        training_time_left = (\n",
    "            self.num_total_steps / self.step - 1.0) * time_sofar if self.step > 0 else 0\n",
    "        print_string = \"epoch {:>3} | lr {:.6f} |lr_p {:.6f} | batch {:>6} | examples/s: {:5.1f}\" + \\\n",
    "            \" | loss: {:.5f} | time elapsed: {} | time left: {}\"\n",
    "        print(print_string.format(self.epoch, self.model_optimizer.state_dict()['param_groups'][0]['lr'],\n",
    "                                  self.model_pose_optimizer.state_dict()['param_groups'][0]['lr'],\n",
    "                                  batch_idx, samples_per_sec, loss,\n",
    "                                  sec_to_hm_str(time_sofar), sec_to_hm_str(training_time_left)))\n",
    "\n",
    "    def log(self, mode, inputs, outputs, losses):\n",
    "        \"\"\"Write an event to the tensorboard events file\n",
    "        \"\"\"\n",
    "        writer = self.writers[mode]\n",
    "        for l, v in losses.items():\n",
    "            writer.add_scalar(\"{}\".format(l), v, self.step)\n",
    "\n",
    "        for j in range(min(4, self.opt.batch_size)):  # write a maxmimum of four images\n",
    "            for s in self.opt.scales:\n",
    "                for frame_id in self.opt.frame_ids:\n",
    "                    writer.add_image(\n",
    "                        \"color_{}_{}/{}\".format(frame_id, s, j),\n",
    "                        inputs[(\"color\", frame_id, s)][j].data, self.step)\n",
    "                    if s == 0 and frame_id != 0:\n",
    "                        writer.add_image(\n",
    "                            \"color_pred_{}_{}/{}\".format(frame_id, s, j),\n",
    "                            outputs[(\"color\", frame_id, s)][j].data, self.step)\n",
    "\n",
    "                writer.add_image(\n",
    "                    \"disp_{}/{}\".format(s, j),\n",
    "                    normalize_image(outputs[(\"disp\", s)][j]), self.step)\n",
    "\n",
    "                if self.opt.predictive_mask:\n",
    "                    for f_idx, frame_id in enumerate(self.opt.frame_ids[1:]):\n",
    "                        writer.add_image(\n",
    "                            \"predictive_mask_{}_{}/{}\".format(frame_id, s, j),\n",
    "                            outputs[\"predictive_mask\"][(\"disp\", s)][j, f_idx][None, ...],\n",
    "                            self.step)\n",
    "\n",
    "                elif not self.opt.disable_automasking:\n",
    "                    writer.add_image(\n",
    "                        \"automask_{}/{}\".format(s, j),\n",
    "                        outputs[\"identity_selection/{}\".format(s)][j][None, ...], self.step)\n",
    "\n",
    "    def save_opts(self):\n",
    "        \"\"\"Save options to disk so we know what we ran this experiment with\n",
    "        \"\"\"\n",
    "        models_dir = os.path.join(self.log_path, \"models\")\n",
    "        if not os.path.exists(models_dir):\n",
    "            os.makedirs(models_dir)\n",
    "        to_save = self.opt.__dict__.copy()\n",
    "\n",
    "        with open(os.path.join(models_dir, 'opt.json'), 'w') as f:\n",
    "            json.dump(to_save, f, indent=2)\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"Save model weights to disk\n",
    "        \"\"\"\n",
    "        save_folder = os.path.join(self.log_path, \"models\", \"weights_{}\".format(self.epoch))\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "\n",
    "        for model_name, model in self.models.items():\n",
    "            save_path = os.path.join(save_folder, \"{}.pth\".format(model_name))\n",
    "            to_save = model.state_dict()\n",
    "            if model_name == 'encoder':\n",
    "                # save the sizes - these are needed at prediction time\n",
    "                to_save['height'] = self.opt.height\n",
    "                to_save['width'] = self.opt.width\n",
    "                to_save['use_stereo'] = self.opt.use_stereo\n",
    "            torch.save(to_save, save_path)\n",
    "\n",
    "        for model_name, model in self.models_pose.items():\n",
    "            save_path = os.path.join(save_folder, \"{}.pth\".format(model_name))\n",
    "            to_save = model.state_dict()\n",
    "            torch.save(to_save, save_path)\n",
    "\n",
    "        save_path = os.path.join(save_folder, \"{}.pth\".format(\"adam\"))\n",
    "        torch.save(self.model_optimizer.state_dict(), save_path)\n",
    "\n",
    "        save_path = os.path.join(save_folder, \"{}.pth\".format(\"adam_pose\"))\n",
    "        if self.use_pose_net:\n",
    "            torch.save(self.model_pose_optimizer.state_dict(), save_path)\n",
    "\n",
    "    def load_pretrain(self):\n",
    "        self.opt.mypretrain = os.path.expanduser(self.opt.mypretrain)\n",
    "        path = self.opt.mypretrain\n",
    "        model_dict = self.models[\"encoder\"].state_dict()\n",
    "        pretrained_dict = torch.load(path)['model']\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if (k in model_dict and not k.startswith('norm'))}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.models[\"encoder\"].load_state_dict(model_dict)\n",
    "        print('mypretrain loaded.')\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"Load model(s) from disk\n",
    "        \"\"\"\n",
    "        self.opt.load_weights_folder = os.path.expanduser(self.opt.load_weights_folder)\n",
    "\n",
    "        assert os.path.isdir(self.opt.load_weights_folder), \\\n",
    "            \"Cannot find folder {}\".format(self.opt.load_weights_folder)\n",
    "        print(\"loading model from folder {}\".format(self.opt.load_weights_folder))\n",
    "\n",
    "        for n in self.opt.models_to_load:\n",
    "            print(\"Loading {} weights...\".format(n))\n",
    "            path = os.path.join(self.opt.load_weights_folder, \"{}.pth\".format(n))\n",
    "\n",
    "            if n in ['pose_encoder', 'pose']:\n",
    "                model_dict = self.models_pose[n].state_dict()\n",
    "                pretrained_dict = torch.load(path)\n",
    "                pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "                model_dict.update(pretrained_dict)\n",
    "                self.models_pose[n].load_state_dict(model_dict)\n",
    "            else:\n",
    "                model_dict = self.models[n].state_dict()\n",
    "                pretrained_dict = torch.load(path)\n",
    "                pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "                model_dict.update(pretrained_dict)\n",
    "                self.models[n].load_state_dict(model_dict)\n",
    "\n",
    "        # loading adam state\n",
    "\n",
    "        optimizer_load_path = os.path.join(self.opt.load_weights_folder, \"adam.pth\")\n",
    "        optimizer_pose_load_path = os.path.join(self.opt.load_weights_folder, \"adam_pose.pth\")\n",
    "        if os.path.isfile(optimizer_load_path):\n",
    "            print(\"Loading Adam weights\")\n",
    "            optimizer_dict = torch.load(optimizer_load_path)\n",
    "            optimizer_pose_dict = torch.load(optimizer_pose_load_path)\n",
    "            self.model_optimizer.load_state_dict(optimizer_dict)\n",
    "            self.model_pose_optimizer.load_state_dict(optimizer_pose_dict)\n",
    "        else:\n",
    "            print(\"Cannot find Adam weights so Adam is randomly initialized\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "options = LiteMonoOptions()\n",
    "opts = options.parse()\n",
    "par_dir = os.getcwd()\n",
    "print(par_dir)\n",
    "\n",
    "trainer = Trainer(opts)\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b145638-e6bf-49d3-96aa-bf149f514731",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73bf341-0dd9-4a99-bae5-3869e8676596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T20:15:14.067183Z",
     "iopub.status.busy": "2023-12-05T20:15:14.066816Z",
     "iopub.status.idle": "2023-12-05T20:15:14.071327Z",
     "shell.execute_reply": "2023-12-05T20:15:14.070932Z",
     "shell.execute_reply.started": "2023-12-05T20:15:14.067165Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install 'git+https://github.com/saadnaeem-dev/pytorch-linear-warmup-cosine-annealing-warm-restarts-weight-decay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3524e4b-2106-49a9-8c82-84caa185118b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-12-05T20:15:14.096024Z",
     "iopub.status.busy": "2023-12-05T20:15:14.095891Z",
     "iopub.status.idle": "2023-12-05T20:15:14.102857Z",
     "shell.execute_reply": "2023-12-05T20:15:14.102441Z",
     "shell.execute_reply.started": "2023-12-05T20:15:14.096013Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/workspace/sunqiao/mymono'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab120797-7846-41b6-9c84-c083ac0200ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T20:15:14.103552Z",
     "iopub.status.busy": "2023-12-05T20:15:14.103396Z",
     "iopub.status.idle": "2023-12-05T20:15:14.106929Z",
     "shell.execute_reply": "2023-12-05T20:15:14.106567Z",
     "shell.execute_reply.started": "2023-12-05T20:15:14.103539Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/workspace/sunqiao/mymono'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
